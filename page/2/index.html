<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"luyilin.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="引而不发，跃如也">
<meta property="og:url" content="http://luyilin.top/page/2/index.html">
<meta property="og:site_name" content="引而不发，跃如也">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="luyilin">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://luyilin.top/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>引而不发，跃如也</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">引而不发，跃如也</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">数据挖掘/04 分类基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-23 09:07:31 / Modified: 14:18:55" itemprop="dateCreated datePublished" datetime="2020-08-23T09:07:31+08:00">2020-08-23</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h1><p><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/1.JPG" alt="1"><br>$$<br>\text{准确率} = \frac{\text{正确预测数}}{预测总数} = \frac{f_{11}+ f_{00}}{f_{11}+f_{00}+f_{10}+f_{01}}<br>$$</p>
<p>$$<br>\text{错误率} = \frac{\text{错误预测数}}{预测总数} = \frac{f_{10}+ f_{01}}{f_{11}+f_{00}+f_{10}+f_{01}}<br>$$</p>
<h1 id="决策树归纳"><a href="#决策树归纳" class="headerlink" title="决策树归纳"></a>决策树归纳</h1><h2 id="建立决策树"><a href="#建立决策树" class="headerlink" title="建立决策树"></a>建立决策树</h2><ol>
<li>Hunt算法<br>以递归方式建立决策树</li>
<li>决策树算法的设计问题<ol>
<li>如何分裂训练记录？</li>
<li>如何停止分裂过程？</li>
</ol>
</li>
</ol>
<h2 id="表示属性测试条件的方法"><a href="#表示属性测试条件的方法" class="headerlink" title="表示属性测试条件的方法"></a>表示属性测试条件的方法</h2><ul>
<li><p>二元属性<br>  产生两个可能的输出</p>
</li>
<li><p>标称属性</p>
<ul>
<li>多路划分</li>
<li>二元划分</li>
</ul>
<p><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/2.JPG" alt="2"></p>
</li>
<li><p>序数属性（暗含序关系）</p>
<p><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/3.JPG" alt="3"></p>
<p>c方法非法</p>
</li>
<li><p>连续属性<br><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/4.JPG" alt="4"></p>
</li>
</ul>
<h2 id="选择最佳划分的度量"><a href="#选择最佳划分的度量" class="headerlink" title="选择最佳划分的度量"></a>选择最佳划分的度量</h2><p>设$P(i|t)$表示给定结点$t$中属于类$i$的纪录所占的比例</p>
<p>选则最佳划分的度量通常是根据划分后子女结点不纯性的程度。不纯的程度越低，类分布就越倾斜。例如，类分布为(0, 1)的结点量有零不纯性，而均衡分布 (0.5,0.5) 的结点具有最高的不纯性。</p>
<p>$$<br>\text { Entropy }(t) =-\sum_{i=0}^{c-1} p(i \mid t) \log _{2} p(i \mid t)<br>$$</p>
<p>$$<br>\operatorname{Gini}(t) =1-\sum_{i=0}^{c-1}[p(i \mid t)]^{2} <br>$$<br>$$<br>\text { Classification } \operatorname{error}(t) =1-\max _{i}[p(i \mid t)]<br>$$</p>
<p>$$<br>其中 c 是类的个数，并且在计算熵时，Olog_0 = 0<br>$$<br><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/5.JPG" alt="5"><br><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/6.JPG" alt="6"></p>
<p>为了确定将试条件的效果，我们需要比较父结点 (划分前) 的不纯程度和子女结点 (划分后) 的不纯程度，它们的差越大，测试条件的效果就越好。增益是一种可以用来确定划分效果的</p>
<p>$$<br>\Delta=I(\text { parent })-\sum_{j=1}^{k} \frac{N\left(v_{j}\right)}{N} I\left(v_{j}\right)<br>$$</p>
<p>其中，I是给定结点的不纯性度量，$N$是父结点上的记录总数，$k$ 是属性值的个数，$N(v_j)$是与子女结点  $v_{j}$  相关联的记录个数。决策树归纳算法通常选则最大化增益$\Delta$的测试条件，因为对所有的测试条件来说，$I(parent)$是一个不变的值，所以最大化增益等价于最小化子女结点的不纯性度量的加权平均值。最后，当选择熵（entropy）作为公式的不纯性度量时，熵的差就是所谓<strong>信息增益(information gain)</strong> $\Delta_{\text {info }}$ </p>
<h2 id="决策树归纳算法"><a href="#决策树归纳算法" class="headerlink" title="决策树归纳算法"></a>决策树归纳算法</h2><p>该算法的输入是训练记录集 E 和属性集F</p>
<ol>
<li>函数 <code>createdNode()</code> 为决策树建立新结点。决策树的结点或者是一个测试条件，记作 <code>node.test_cond</code>，或者是一个类标号，记作 <code>node.label</code></li>
<li>函数 <code>find_best_split()</code>确定应当选择哪个属性作为划分训练记录的测试条件。可用熵、Gini 指标和 $\chi^2$ 统计量进行度量。</li>
<li>函数 <code>Classify()</code> 为叶结点确定类标号。对于每个叶结点  t,  令  $p(i \mid t)$  表示该结点上属于类 $i$ 的训练记录所占的比例，在大多数情况下，都将叶结点指派到具有多数记录的类:</li>
</ol>
<p>$$\text {leaf.label}=\underset{i}{\operatorname{argmax}} p(i \mid t)$$</p>
<p>其中，操作 argmax 返回最大化  $p(i \mid t)$  的参数值  $i。p(i \mid t)$  除了提供确定叶结点类标号所需要的信息之 外，还可以用来估计分配到叶结点  $t$  的记录属于类  $i$  的概率。</p>
<ol start="4">
<li>函数 <code>stopping_cond()</code> 通过检查是否所有的记录都属于同一个类, 或者都具有相同的属性值，决定是否终止决策树的增长。终止递归函数的另一种方法是，检查记录数是否小与某个最小阈值。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">TreeGrowth(E,F)</span><br><span class="line">    <span class="keyword">if</span> stopping_cond(E,F) = <span class="literal">True</span>:</span><br><span class="line">        leaf = creatNode()</span><br><span class="line">        leaf.label = Classify(E)</span><br><span class="line">        <span class="keyword">return</span> leaf</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        root = creatNode()</span><br><span class="line">        root.test_cond = find_best_split(E,F)</span><br><span class="line">        V = &#123;v| v 是 root.test_cond 的一个可能输出&#125;</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> V:</span><br><span class="line">            Ev = &#123;e|root.test_cond(e) = v 且e <span class="keyword">in</span> E&#125;</span><br><span class="line">            child = TreeGrowth(Ev,F)</span><br><span class="line">            将child加入树中，并添加边(root-&gt;child)标记为v</span><br><span class="line">    <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="决策树特点"><a href="#决策树特点" class="headerlink" title="决策树特点"></a>决策树特点</h2><ol>
<li>不要求任何先验经验，不假定属性服从概率分布</li>
<li>NP完全问题</li>
<li>决策树一旦建立，分类速度很快，最坏$O(w),w$为深度</li>
<li>有较好的鲁棒性</li>
<li>冗余属性不会对决策树准确性造成不良影响</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/22/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/03%20%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/22/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/03%20%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">数据挖掘/03 探索数据</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-22 09:09:04" itemprop="dateCreated datePublished" datetime="2020-08-22T09:09:04+08:00">2020-08-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-06 16:09:52" itemprop="dateModified" datetime="2020-09-06T16:09:52+08:00">2020-09-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="汇总统计"><a href="#汇总统计" class="headerlink" title="汇总统计"></a>汇总统计</h1><ul>
<li><p>量化的</p>
</li>
<li><p>用单个数据或数的小集合捕获可能很大的值集的各种特征</p>
</li>
<li><p>例子：家庭平均收入，四年完成本科学业的比例</p>
<h2 id="频率和众数"><a href="#频率和众数" class="headerlink" title="频率和众数"></a>频率和众数</h2><p>分类属性比较合适，连续数据往往不适合</p>
<h2 id="百分位数"><a href="#百分位数" class="headerlink" title="百分位数"></a>百分位数</h2><p>对于有序数集，考虑百分位数</p>
<h2 id="均值与中位数"><a href="#均值与中位数" class="headerlink" title="均值与中位数"></a>均值与中位数</h2><p>对于连续数据的描述</p>
</li>
<li><p>截断均值：丢弃部分最高最低数据后的均值</p>
<h2 id="散布度量：极差与方差"><a href="#散布度量：极差与方差" class="headerlink" title="散布度量：极差与方差"></a>散布度量：极差与方差</h2><p>连续数据的另一个常用汇总统计</p>
</li>
<li><p>极差：最大减最小</p>
</li>
<li><p>方差</p>
</li>
<li><p>标准差：方差的平方根</p>
</li>
<li><p>绝对平均偏差（ADD）：<br>$$ADD(x) = \frac{1}{m}\sum_{i = 1}^m|x_i - \bar{x}|$$</p>
</li>
<li><p>中位数绝对偏差：<br>$$MAD(x) = median({|x_1 - \bar{x}|,…,|x_m - \bar{x}|})$$</p>
</li>
<li><p>四分卫数极差<br>$$IRQ = x_{0.75} - x_{0.25}$$</p>
</li>
</ul>
<h2 id="多元汇总统计"><a href="#多元汇总统计" class="headerlink" title="多元汇总统计"></a>多元汇总统计</h2><p>散布：协方差矩阵</p>
<p>其中，$S$ 的第$i j$个元素  $s_{i j}$  是数据的第  $i$  个和第  $j$  个属性的协方差。这样，如果  $x_{i}$  和  $x_{j}$  分别是第  $i$  个和第 $j$ 个属性，则<br>$$<br>s_{i j}=\operatorname{covariance}\left(x_{i}, x_{j}\right)<br>$$</p>
<p>而 $covariance  \left(x_{i}, x_{j}\right)$  由</p>
<p>$$<br>\operatorname{covariance}\left(x_{i},x_{j}\right)=\frac{1}{m-1}\sum_{k=1}^{m}\left(x_{ki}-\bar{x}<em>{i}\right)\left(x</em>{kj}-\bar{x}_{j}\right)<br>$$</p>
<p>给出,其中  $x_{k i}$  和  $x_{k j}$  分别是第  $k$  个对象的第  $i$  和第  $j$  个属性的值. 注意, $covariance  \left(x_{i}, x_{i}\right)=  variance  \left(x_{i}\right)$  </p>
<p>这样，协方差矩阵的对角线上是属性的方差。</p>
<p>两个属性的协方差是两个属性一起变化并依赖于变量大小的度量。协方差的值接近于 0 表明 两个变最不具有（线性）关系，但是不能仅观察协方差的值来确定两个变量之间的关联程度。 因为两个属性的相关性直接指出两个属性（线性）相关的程度，对于数据探索，相关性比协方差更可取。相关矩阵（correlation matrix）$R$ 的第  $i j$个元素是数据 的第 $i$ 个和第 $j$ 个属性之间的相关性。如果  $x_{i}$  和  $x_{j}$ 分别是第  $i$  个和第  $j$  个属性，则<br>$$<br>r_{i j}=\text { correlation }\left(x_{i}, x_{j}\right)=\frac{\text { covariance }\left(x_{i}, x_{j}\right)}{s_{i} s_{j}}<br>$$</p>
<p>其中，$s_i$和  $s_{j}$  分别是  $x_{i}$  和  $x_{j}$  的方差。R 的对角线上的元素是 $correlation  \left(x_{l}, x_{i}\right)=1$,  而其他元素在-1 和 1 之间。考虑包含每对对像而不是每对属性之间相关性的相关矩阵也是有用的。</p>
<h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p>茎叶图，直方图，二维直方图，盒状图，饼图，散布图，等高线图，曲面图，矢量场图，低维切片</p>
<h1 id="联机分析处理-OLAP-和多维数据分析"><a href="#联机分析处理-OLAP-和多维数据分析" class="headerlink" title="联机分析处理(OLAP)和多维数据分析"></a>联机分析处理(OLAP)和多维数据分析</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/" class="post-title-link" itemprop="url">机器学习/应用机器学习的建议</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-21 20:19:46" itemprop="dateCreated datePublished" datetime="2020-08-21T20:19:46+08:00">2020-08-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-23 21:19:41" itemprop="dateModified" datetime="2020-08-23T21:19:41+08:00">2020-08-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="评估算法性能"><a href="#评估算法性能" class="headerlink" title="评估算法性能"></a>评估算法性能</h1><p>如何判断假设函数是否过拟合？ 对假设函数画图</p>
<p>维数过多？按7：3的比例划分成训练集和测试集</p>
<ul>
<li>对于线性回归模型，计算$J(\theta)$,计算测试集的误差</li>
<li>对于逻辑回归模型，除了计算代价函数，还可以计算误分类比率</li>
</ul>
<p>$$err\left(h_{\theta}(x), y\right)= 1 \text { if } h(x) \geq 0.5 \text { and } y=0 \text { , or if } h(x)&lt;0.5 \text { and } y=1$$<br>$$err\left(h_{\theta}(x), y\right)=  0 \text { Otherwise }$$</p>
<p>然后对计算结果求平均</p>
<p>$$<br>Testerror = \frac{\sum err}{m}<br>$$</p>
<h1 id="模型选择和交叉验证集"><a href="#模型选择和交叉验证集" class="headerlink" title="模型选择和交叉验证集"></a>模型选择和交叉验证集</h1><p>假设我们要在10个不同次数的二项式模型之间进行选择，越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。</p>
<p>使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集。</p>
<ul>
<li>模型选择的方法为：</li>
</ul>
<ol>
<li><p>使用训练集训练出10个模型</p>
</li>
<li><p>用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</p>
</li>
<li><p>选取代价函数值最小的模型</p>
</li>
<li><p>用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）</p>
</li>
</ol>
<p>Training error:<br>$$J_{t r a i n}(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2} $$</p>
<p>Cross Validation error:<br>$$ J_{c v}(\theta)=\frac{1}{2 m_{c v}} \sum_{i=1}^{m}\left(h_{\theta}\left(x_{c v}^{(i)}\right)-y_{c v}^{(i)}\right)^{2} $$<br>Test error:<br>$$ J_{\text {test}}(\theta)=\frac{1}{2 m_{\text {test}}} \sum_{i=1}^{m_{\text {test}}}\left(h_{\theta}\left(x_{c v}^{(i)}\right)-y_{c v}^{(i)}\right)^{2} $$</p>
<h1 id="诊断偏差和方差"><a href="#诊断偏差和方差" class="headerlink" title="诊断偏差和方差"></a>诊断偏差和方差</h1><p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/1.JPG" alt="1"><br>横轴从欠拟合逐渐走向过拟合</p>
<p>high bias (偏差) 意味模型简单，欠拟合<br>high variance(方差) 意味模型复杂，过拟合</p>
<p>训练集误差和交叉验证集误差近似时：偏差/欠拟合 交叉验证集误差远大于训练集误差时：方差/过拟合</p>
<h1 id="正则化和偏差-方差"><a href="#正则化和偏差-方差" class="headerlink" title="正则化和偏差/方差"></a>正则化和偏差/方差</h1><p>$$<br>J(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}+\frac{\lambda}{2 m} \sum_{j=1}^{m} \theta_{j}^{2}$$</p>
<p>$$<br>J_{\text {train}}(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}$$</p>
<p>$$<br>J_{c v}(\theta)=\frac{1}{2 m_{c v}} \sum_{i=1}^{m_{c v}}\left(h_{\theta}\left(x_{c v}^{(i)}\right)-y_{c v}^{(i)}\right)^{2}<br>$$</p>
<p>选择的方法为：</p>
<p>$\lambda = 0,0.01,0.02,0.04,…10$</p>
<ol>
<li>使用训练集训练出12个不同程度正则化的模型</li>
<li>用12个模型分别对交叉验证集计算的出交叉验证误差</li>
<li>选择得出交叉验证误差最小的模型</li>
<li>运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：</li>
</ol>
<p>当$\lambda$  较小时，训练集误差较小（过拟合）而交叉验证集误差较大 </p>
<p>随着$\lambda$的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</p>
<p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/2.JPG" alt="2"></p>
<h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><h2 id="最开始"><a href="#最开始" class="headerlink" title="最开始"></a>最开始</h2><p>画出$J_{\text {train}}(\theta)$,$J_{c v}(\theta)$关于训练集m个数的变化趋势</p>
<p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/3.JPG" alt="3"></p>
<h2 id="进一步讨论"><a href="#进一步讨论" class="headerlink" title="进一步讨论"></a>进一步讨论</h2><p>cv集的数量不变，考虑用欠拟合的模型，随着训练集的增大，误差增大但是会最终停留在一个较高值，cv同理先减小后停留在较高值。</p>
<p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/4.JPG" alt="4"></p>
<ul>
<li>高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。</li>
</ul>
<p>考虑过拟合的情况，随着训练集的增大，训练集误差增大，交叉验证集误差减小，但会一直减小，增大数据集对于过拟合的情况有用。</p>
<ul>
<li>高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。<h1 id="下一步做什么"><a href="#下一步做什么" class="headerlink" title="下一步做什么"></a>下一步做什么</h1></li>
</ul>
<ol>
<li>获得更多的训练样本——解决高方差</li>
<li>尝试减少特征的数量——解决高方差</li>
<li>尝试获得更多的特征——解决高偏差</li>
<li>尝试增加多项式特征——解决高偏差</li>
<li>尝试减少正则化程度λ——解决高偏差</li>
<li>尝试增加正则化程度λ——解决高方差</li>
</ol>
<h2 id="神经网络的方差和偏差"><a href="#神经网络的方差和偏差" class="headerlink" title="神经网络的方差和偏差"></a>神经网络的方差和偏差</h2><p>使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。 </p>
<p>通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">数据挖掘/数据</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-21 08:36:15" itemprop="dateCreated datePublished" datetime="2020-08-21T08:36:15+08:00">2020-08-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-06 16:11:44" itemprop="dateModified" datetime="2020-09-06T16:11:44+08:00">2020-09-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="属性与度量"><a href="#属性与度量" class="headerlink" title="属性与度量"></a>属性与度量</h2><h3 id="属性的不同类型"><a href="#属性的不同类型" class="headerlink" title="属性的不同类型"></a>属性的不同类型</h3><ul>
<li>数值的如下属性（操作）常常用来描述属性</li>
</ul>
<ol>
<li>相异性</li>
<li>序</li>
<li>加法</li>
<li>乘法</li>
</ol>
<p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/1.JPG" alt="1"></p>
<p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/2.JPG" alt="2"></p>
<ul>
<li><p>用值的个数描述属性： 离散的、连续的</p>
</li>
<li><p>非对称属性<br>对于非对称属性，出现非0值才使重要的</p>
</li>
</ul>
<h2 id="数据集的类型"><a href="#数据集的类型" class="headerlink" title="数据集的类型"></a>数据集的类型</h2><ol>
<li>数据集的一般特性<br>维度、稀疏性、分辨率</li>
<li>记录数据<ul>
<li>事务数据：项的集合的集族，纪录的集合</li>
<li>数据矩阵</li>
<li>稀疏数据矩阵</li>
</ul>
</li>
<li>基于图形的数据（纪录对象之间的联系、图形作为对象如化学结构）</li>
<li>有序数据</li>
<li>时序数据</li>
<li>空间数据</li>
</ol>
<h1 id="数据质量"><a href="#数据质量" class="headerlink" title="数据质量"></a>数据质量</h1><ol>
<li>数据质量问题的纠正和检测</li>
<li>数据清理</li>
</ol>
<h2 id="测量和数据收集问题"><a href="#测量和数据收集问题" class="headerlink" title="测量和数据收集问题"></a>测量和数据收集问题</h2><ol>
<li>测量误差和收集误差</li>
<li>噪声和伪像<br> 噪声是测量误差的随机部分<br> <img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/3.JPG" alt="3"><br> 伪像： 数据出现的确定性失真</li>
<li>精度、偏倚和准确率<br>精度：重复测量值之间的接近程度，通常用集合的标准差度量<br>偏倚：测量值与被测量值之间的系统的变差，用集合的均值与测出的已知值之间的差度量</li>
</ol>
<p>   准确率：被测量的测量值与实际值之间的接近度</p>
<ol start="4">
<li><p>离群点<br> 合法的对象、异常</p>
</li>
<li><p>遗漏值</p>
<ul>
<li>删除数据对象或属性</li>
<li>估计遗漏值</li>
<li>忽略遗漏值（仅是用没有遗漏值的属性进行计算）</li>
</ul>
</li>
<li><p>不一致的值（需要对数据更正）</p>
</li>
<li><p>重复数据</p>
</li>
</ol>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><blockquote>
<p>数据是高质量的，如果它适合预期的应用</p>
</blockquote>
<ul>
<li>时效性</li>
<li>相关性</li>
</ul>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="聚集"><a href="#聚集" class="headerlink" title="聚集"></a>聚集</h2><ul>
<li>将两个或多个对象合并成单个对象</li>
<li>聚集是删除属性的过程，或者压缩特定属性不同值个数的过程，如将日期从可能的365天压缩到12个月</li>
</ul>
<p>动机：</p>
<ul>
<li>节约内存、时间</li>
<li>起到范围或者标度转换的作用</li>
<li>更稳定</li>
</ul>
<h2 id="抽样"><a href="#抽样" class="headerlink" title="抽样"></a>抽样</h2><ul>
<li><p>选择数据对象子集进行分析的常用方法</p>
</li>
<li><p>动机：压缩数据量，以便使用更好但是开销更大的算法</p>
</li>
<li><p>主要原理：<br>样本数据在我们感兴趣的性质上（如平均值）域原数据集近似，则样本室友代表性的，进而使用样本和使用整个数据集的效果几乎一样</p>
</li>
</ul>
<ol>
<li>抽样方法<ul>
<li>简单随机抽样（有放回、无放回）</li>
<li>分层抽样</li>
</ul>
</li>
</ol>
<p>注： 抽样会导致一定程度上的信息损失</p>
<ol start="2">
<li>渐进抽样<br>从小样本开始，逐渐增加样本容量直至的达到足够容量的样本</li>
</ol>
<h2 id="维归约"><a href="#维归约" class="headerlink" title="维归约"></a>维归约</h2><ul>
<li>将一些旧属性合并在一起来降低数据集的维度</li>
</ul>
<p>注：通过选择旧属性的子集得到新属性，这种维归约成为特征子集选择或特征选择</p>
<ul>
<li>删除不相关的特征并降低噪声，避免维灾难</li>
<li>关键： 主成分分析（PCA）</li>
</ul>
<h2 id="特征子集选择"><a href="#特征子集选择" class="headerlink" title="特征子集选择"></a>特征子集选择</h2><ul>
<li>选择特征的一个子集</li>
</ul>
<h3 id="特征选择方法"><a href="#特征选择方法" class="headerlink" title="特征选择方法"></a>特征选择方法</h3><ol>
<li>嵌入方法</li>
</ol>
<p>决策树分类器<br>2. 过滤方法</p>
<p>在数据挖掘算法之前进行特征选择</p>
<ol start="3">
<li>包装方法<br>将可能的特征子集作为数据挖掘算法的输入，选出产生最好结果的子集</li>
</ol>
<ul>
<li>也可以进行特征加权</li>
</ul>
<p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/4.JPG" alt="4"></p>
<h2 id="特征创建"><a href="#特征创建" class="headerlink" title="特征创建"></a>特征创建</h2><ol>
<li>特征提取</li>
<li>映射数据到新的空间<br>傅里叶变换</li>
<li>特征构造：密度</li>
</ol>
<h2 id="离散化和二元化"><a href="#离散化和二元化" class="headerlink" title="离散化和二元化"></a>离散化和二元化</h2><ol>
<li>二元化<br><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/5.JPG" alt="5"></li>
<li>连续属性离散化<ul>
<li>非监督离散化：等宽、等频率（将相同数量的对象放进每个区间）、等深、K均值</li>
<li>监督化离散：</li>
</ul>
</li>
</ol>
<p>定义  <strong>熵</strong>：</p>
<p>设$k$是不同的类标号数，$m_i$是某划分的第$i$个区间中值的个数，$m_{ij}$是区间$i$中类$j$的值的个数，第$i$个区间的熵$e_i$由如下等式给出<br>$$e_i = -\sum_{j = 1}^k\ p_{ij}\ log_2P_{ij}$$</p>
<p>其中<br>$$p_{ij} = m_{ij}/m_{i}$$<br>是第$i$个区间中类$j$的概率。该划分的总熵$e$是每个区间熵的加权平均，即</p>
<p>$$e = \sum_{i = 1}^n\ w_ie_i$$</p>
<p>其中<br>$$w_i = m_i/m,\ m为值的个数$$<br><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/6.JPG" alt="6"></p>
<h2 id="变量变换"><a href="#变量变换" class="headerlink" title="变量变换"></a>变量变换</h2><ol>
<li><p>简单函数<br>$$x^k,log \ x,e^x,\sqrt{x},|x|$$</p>
</li>
<li><p>规范化或标准化</p>
</li>
</ol>
<p>统计学中的标准化：<br>$$x’ = \frac{(x - \bar{x})}{s_x}$$</p>
<p>$s_x为标准差$</p>
<p>数据挖掘中的标准化：</p>
<ol>
<li>用中位数取代均值</li>
<li>用标准绝对差取代标准差</li>
</ol>
<p>标准绝对差：<br>$$\sigma = \sum_{i = 1}^m|x_i - \mu_i|$$</p>
<p>其中，m是对象个数，$\mu$是均值或中位数</p>
<h1 id="相似性和相异性的度量"><a href="#相似性和相异性的度量" class="headerlink" title="相似性和相异性的度量"></a>相似性和相异性的度量</h1><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul>
<li><p>相似度： 两个对象之间的相似程度。取值范围：0（不相似）-1（相似）</p>
</li>
<li><p>相异度（距离）：两个对象的差异程度。取值范围： 0（相同）-1/正无穷</p>
</li>
</ul>
<h3 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h3><p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/7.JPG" alt="7"></p>
<h2 id="简单属性"><a href="#简单属性" class="headerlink" title="简单属性"></a>简单属性</h2><p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/8.JPG" alt="8"></p>
<h2 id="数据对象之间的相异度"><a href="#数据对象之间的相异度" class="headerlink" title="数据对象之间的相异度"></a>数据对象之间的相异度</h2><p>定义r-范数</p>
<ul>
<li>r = 1 为曼哈顿距离</li>
<li>r = 2 为欧几里得距离</li>
<li>r = $+\infin$为属性之间的对大值</li>
</ul>
<p>满足非负性，对称性，三角不等式，进而引入度量</p>
<h2 id="数据对象之间的相似度"><a href="#数据对象之间的相似度" class="headerlink" title="数据对象之间的相似度"></a>数据对象之间的相似度</h2><p>对于相似度，三角不等式通常不成立</p>
<h2 id="邻近性度量的例子"><a href="#邻近性度量的例子" class="headerlink" title="邻近性度量的例子"></a>邻近性度量的例子</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">机器学习/神经网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-14 09:03:29" itemprop="dateCreated datePublished" datetime="2020-08-14T09:03:29+08:00">2020-08-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-19 21:10:53" itemprop="dateModified" datetime="2020-08-19T21:10:53+08:00">2020-08-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="非线性假设"><a href="#非线性假设" class="headerlink" title="非线性假设"></a>非线性假设</h1><ul>
<li>线性回归和逻辑回归的缺点：当特征过多时，计算会过于复杂</li>
</ul>
<h1 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h1><p><img src="/2020/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.png" alt="1"></p>
<p>其中$x_1,x_2,x_3$是输入单元，$a_1,a_2,a_3$是中间单元，负责数据处理，最后是输出单元。</p>
<p>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。</p>
<p>第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。我们为每一层都增加一个偏差单位（bias unit）</p>
<ul>
<li>符号表示：<br>$a_i^{(j)}代表第j层的第i个激活单元,\theta^{(j)}代表从第j层映射到第j + 1层时的权重的矩阵$</li>
</ul>
<p>对于上图所示的模型，激活单元和输出分别表达为：</p>
<p>$$<br>a_{1}^{(2)}=g\left(\Theta_{10}^{(1)} x_{0}+\Theta_{11}^{(1)} x_{1}+\Theta_{12}^{(1)} x_{2}+\Theta_{13}^{(1)} x_{3}\right)<br>$$</p>
<p>$$<br>a_{2}^{(2)}=g\left(\Theta_{20}^{(1)} x_{0}+\Theta_{21}^{(1)} x_{1}+\Theta_{22}^{(1)} x_{2}+\Theta_{23}^{(1)} x_{3}\right)<br>$$</p>
<p>$$<br>a_{3}^{(2)}=g\left(\Theta_{30}^{(1)} x_{0}+\Theta_{31}^{(1)} x_{1}+\Theta_{32}^{(1)} x_{2}+\Theta_{33}^{(1)} x_{3}\right)<br>$$</p>
<p>$$<br>h_{\Theta}(x)=a_1^{(3)} = g\left(\Theta_{10}^{(2)} a_{0}^{(2)}+\Theta_{11}^{(2)} a_{1}^{(2)}+\Theta_{12}^{(2)} a_{2}^{(2)}+\Theta_{13}^{(2)} a_{3}^{(2)}\right)<br>$$</p>
<p>如果一个网络在$j$层有$s_j$个神经元，$j + 1$层有$s_{j+1}$个神经元，那么$\Theta^{(j)}$的维数是$s_{j + 1}\times(s_j + 1)$</p>
<h1 id="多类分类"><a href="#多类分类" class="headerlink" title="多类分类"></a>多类分类</h1><p>输出层多个输出，分别表示每一项的是或者非</p>
<h1 id="符号表示"><a href="#符号表示" class="headerlink" title="符号表示"></a>符号表示</h1><p>$m$:样本数量</p>
<p>$L$:神经网络层数</p>
<p>$S_i$:每层的神经元数目</p>
<p>二分类：$S_L = 1, y = 0,1$表示哪一类</p>
<p>$K$分类($L &gt; 2$) : $S_L = K$, $y_i = 1$表示分到第$i$类</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><ul>
<li><p>逻辑回归<br>$$J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$$</p>
</li>
<li><p>神经网络<br>在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些</p>
</li>
</ul>
<p>$$J(\Theta)=-\frac{1}{m}\sum_{i=1}^{m}\sum_{k=1}^{k}\left[y_{k}^{(i)}\log\left(h_{\Theta}\left(x^{(i)}\right)\right)<em>{k}+\left(1-y</em>{k}^{(i)}\right)\log\left(1-\left(h_{\Theta}\left(x^{(i)}\right)\right)<em>{k}\right)\right]+\frac{\lambda}{2m}\sum</em>{l=1}^{L-1}\sum_{i=1}^{s_{l}}\sum_{j=1}^{s_{l}+1}\left(\Theta_{ji}^{(l)}\right)^{2}$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">机器学习/逻辑回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-12 08:50:44" itemprop="dateCreated datePublished" datetime="2020-08-12T08:50:44+08:00">2020-08-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-20 14:57:47" itemprop="dateModified" datetime="2020-09-20T14:57:47+08:00">2020-09-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>$y$ 是一个离散值</p>
<p>线性回归此时可能准确度降低，并且预测值可能远大于1或者小于0</p>
<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>线性回归：<br>$$h_\theta(x) = \theta^TX$$<br>逻辑回归：<br>$$h_\theta(x) = g(\theta^TX)$$</p>
<p>其中<br>$$g(x) = \frac{1}{1 + e^{-x}}$$</p>
<p>合并有<br>$$h_\theta(x) = \frac{1}{1 + e^{-\theta^TX}}$$</p>
<p>这里$h$的作用是输出$y = 1$的可能性，即<br>$$h_\theta (x) = P(y = 1|x;\theta )$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-z))</span><br></pre></td></tr></table></figure>

<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>线性回归<br>$$J(\theta) = \frac{1}{m}\sum_{i = 1}^m\frac{1}{2}(h_{\theta}(x^{(i)})-y^{(i)})^2$$</p>
<p>$$J(\theta) = \frac{1}{m}\sum_{i = 1}^mCost(h_{\theta}(x^{(i)}),y^{(i)})$$</p>
<p>逻辑回归<br>$$\operatorname{Cost}\left(h_{\theta}(x), y\right)=\left{\begin{aligned}<br>-\log \left(h_{\theta}(x)\right) &amp; \text { if } y=1 \<br>-\log \left(1-h_{\theta}(x)\right) &amp; \text { if } y=0<br>\end{aligned}\right.$$</p>
<ul>
<li>实际的 $y = 1$ 且 $h_\theta(x)$ 也为 1时误差为 0，当$y = 1$但$h_\theta(x)$不为1时误差随着$h_\theta(x)$变小而变大；当实际的$y = 0$  且$h_\theta(x)$也为 0 时代价为 0，当$y = 0$ 但$h_\theta(x)$不为0时误差随着$h_\theta(x)$的变大而变大。</li>
</ul>
<p>变形有<br>$$\operatorname{cost}\left(h_{\theta}(x), y\right)=-y \times \log \left(h_{\theta}(x)\right)-(1-y) \times \log \left(1-h_{\theta}(x)\right)$$</p>
<p>$$J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$$</p>
<p>$$h_\theta(x) = \theta^TX$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(theta, X, y)</span>:</span></span><br><span class="line">    theta = np.matrix(theta)</span><br><span class="line">    X = np.matrix(X)</span><br><span class="line">    y = np.matrix(y)</span><br><span class="line">    first = np.multiply(-y, np.log(sigmoid(X* theta.T)))</span><br><span class="line">    second = np.multiply((<span class="number">1</span> - y), np.log(<span class="number">1</span> - sigmoid(X* theta.T)))</span><br><span class="line">    <span class="keyword">return</span> np.sum(first - second) / (len(X))</span><br></pre></td></tr></table></figure>

<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>$$J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$$<br>考虑： </p>
<p>$$h_{\theta}\left(x^{(i)}\right)=\frac{1}{1+e^{-\theta^{T} x^{(i)}}}$$</p>
<p>则:<br>$$<br>\begin{aligned}<br>&amp;y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right) \<br>&amp;=y^{(i)} \log \left(\frac{1}{1+e^{-\theta^{T} x^{(i)}}}\right)+\left(1-y^{(i)}\right) \log \left(1-\frac{1}{\left.1+e^{-\theta^{T} x^{(i)}}\right)}\right)\<br>&amp;=-y^{(i)} \log \left(1+e^{-\theta^{T} x^{(i)}}\right)-\left(1-y^{(i)}\right) \log \left(1+e^{\theta^{T} x^{(i)}}\right)<br>\end{aligned}<br>$$</p>
<p>所以:</p>
<p>$$<br>\begin{aligned}<br>\frac{\partial}{\partial \theta_{j}} J(\theta)<br>&amp;=\frac{\partial}{\partial \theta_{j}}\left[-\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \log \left(1+e^{-\theta^{T} x^{(i)}}\right)-\left(1-y^{(i)}\right) \log \left(1+e^{\theta^{T} x^{(i)}}\right)\right]\right]\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \frac{-x_{j}^{(i)} e^{-\theta^{T} x^{(i)}}}{1+e^{-\theta^{T} x^{(i)}}}-\left(1-y^{(i)}\right) \frac{x_{j}^{(i)} e^{\theta^{T} x^{(i)}}}{1+e^{\theta^{T} x^{(i)}}}\right]\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)}\frac{x_{j}^{(i)}}{1+e^{\theta^{T} x^{(i)}}}-\left(1-y^{(i)}\right) \frac{x_{j}^{(i)} e^{\theta^T} x^{(i)}}{1+e^{\theta^{T} x^{(i)}}}\right] \<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m} \frac{y^{(i)} x_{j}^{(i)}-x_{j}^{(i)} e^{\theta T_{x}(i)}+y^{(i)} x_{j}^{(i)} e^{\theta^{T} x^{(i)}}}{1+e^{\theta T_{x}(i)}} \<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m} \frac{y^{(i)}\left(1+e^{\theta^{T} x^{(i)}}\right)-e^{\ell^{T} x^{(i)}}}{1+e^{\theta^{T} x^{(i)}}} x_{j}^{(i)}\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left(y^{(i)}-\frac{e^{\theta^{T} x^{(i)}}}{1+e^{\theta^{T} x^{(i)}}}\right) x_{j}^{(i)} \<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left(y^{(i)}-\frac{1}{\left(1 + e^{-\theta^{T}x^{(i)}}\right)}\right)x_{j}^{(i)}\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)}-h_{\theta}\left(x^{(i)}\right)\right] x_{j}^{(i)}\<br>&amp;=\frac{1}{m} \sum_{i=1}^{m}\left[h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right] x_{j}^{(i)}<br>\end{aligned}<br>$$</p>
<p>得到了与线性回归类似的表达式($h_\theta(x)$不同)</p>
<ul>
<li>在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。</li>
</ul>
<h2 id="一对多的分类"><a href="#一对多的分类" class="headerlink" title="一对多的分类"></a>一对多的分类</h2><p>对各个类别进行一次二分类即可</p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>解决过拟合问题</p>
<h2 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h2><p>$$J(\theta) = \frac{1}{2m}\left[\sum_{i = 1}^m(h_\theta(x^{(i)})-y^{(i)})^2 + \lambda\sum_{j = 1}^n\theta_j^2\right]$$</p>
<ul>
<li>注： $\theta_j$的求和项从1开始</li>
</ul>
<h2 id="正则化线性回归"><a href="#正则化线性回归" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h2><h3 id="梯度下降-1"><a href="#梯度下降-1" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>$$<br>\begin{array}{l}<br>\theta_{0}:=\theta_{0}-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{0}^{(i)}\right) \<br>\theta_{j}:=\theta_{j}-a\left[\frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}+\frac{\lambda}{m} \theta_{j}\right]\right.<br>\end{array}<br>$$</p>
<p>对于$j = 1,2,…,n$可改为</p>
<p>$$\theta_{j}:=\theta_{j}\left(1-a \frac{\lambda}{m}\right)-a \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}$$</p>
<h3 id="正则方程"><a href="#正则方程" class="headerlink" title="正则方程"></a>正则方程</h3><p>$$<br>\theta=\left(X^{T} X+\lambda\left[\begin{array}{ccc}<br>0 \<br>&amp;1&amp; \<br>&amp;&amp; \ddots \<br>&amp;&amp;&amp;1<br>\end{array}\right]\right)^{-1} X^{T} y<br>$$</p>
<p>矩阵尺寸$(n + 1)(n + 1)$</p>
<h2 id="正则化的逻辑回归模型"><a href="#正则化的逻辑回归模型" class="headerlink" title="正则化的逻辑回归模型"></a>正则化的逻辑回归模型</h2><p>$$J(\theta)=\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)-\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">costReg</span><span class="params">(theta, X, y, learningRate)</span>:</span></span><br><span class="line">    theta = np.matrix(theta)</span><br><span class="line">    X = np.matrix(X)</span><br><span class="line">    y = np.matrix(y)</span><br><span class="line">    first = np.multiply(-y, np.log(sigmoid(X*theta.T)))</span><br><span class="line">    second = np.multiply((<span class="number">1</span> - y), np.log(<span class="number">1</span> - sigmoid(X*theta.T)))</span><br><span class="line">    reg = (learningRate / (<span class="number">2</span> * len(X))* np.sum(np.power(theta[:,<span class="number">1</span>:theta.shape[<span class="number">1</span>]],<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> np.sum(first - second) / (len(X)) + regpython</span><br></pre></td></tr></table></figure>


<p>$$<br>\theta_{0}:=\theta_{0}-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{0}^{(i)}\right) \<br>\theta_{j}:=\theta_{j}-a\left[\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}+\frac{\lambda}{m} \theta_{j}\right] \<br>$$</p>
<p>$\ for\ j = 1,2,…,n$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%20%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%20%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/" class="post-title-link" itemprop="url">机器学习/多变量线性回归 正规方程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-11 09:11:34 / Modified: 11:03:55" itemprop="dateCreated datePublished" datetime="2020-08-11T09:11:34+08:00">2020-08-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h1><p>n：特征的数量</p>
<p>$x^{(i)} = \begin{bmatrix}<br>1416<br>\3<br>\2<br>\40<br>\end{bmatrix}$  表示第$i$个训练实例</p>
<p>$x^{(i)}_2 = 3$</p>
<p>代表特征矩阵中第$i$行的第$j$个特征，也就是第$i$个训练实例的第$j$个特征。</p>
<h1 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h1><h2 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h2><p>$$h_{\theta}(x)=\theta_{0}+\theta_{1} x_{1}+\theta_{2} x_{2}+\ldots+\theta_{n} x_{n}$$</p>
<p>引入$x_0 = 1$,则<br>$$h_{\theta}(x)=\theta_{0}x_0+\theta_{1} x_{1}+\theta_{2} x_{2}+\ldots+\theta_{n} x_{n}$$</p>
<p>x成为一个n+1维的向量<br>$x = \begin{bmatrix}<br>x_0<br>\x_1<br>\…<br>\x_n<br>\end{bmatrix}$ </p>
<p>从而<br>$$h_\theta(x) = \theta^Tx$$</p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>$$J\left(\theta\right)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(X, y, theta)</span>:</span></span><br><span class="line">    inner = np.power(((X * theta.T) - y), <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> np.sum(inner) / (<span class="number">2</span> * len(X))</span><br></pre></td></tr></table></figure>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>$$\theta_{j}:=\theta_{j}-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x^{(i)}_j\right) $$</p>
<p>$\alpha = 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10…$</p>
<h1 id="特征缩放-Feature-Scaling"><a href="#特征缩放-Feature-Scaling" class="headerlink" title="特征缩放 (Feature Scaling)"></a>特征缩放 (Feature Scaling)</h1><p>目的：使梯度下降更快收敛</p>
<ul>
<li>均值归一化</li>
</ul>
<p>将所有特征的尺度都尽量缩放到-1到1之间。</p>
<p>$$x_n = \frac{x_n - \mu_n}{s_n}$$<br>其中$\mu_n$是平均值，$s_n$是标准差（max-min）</p>
<h1 id="特征和多项式回归"><a href="#特征和多项式回归" class="headerlink" title="特征和多项式回归"></a>特征和多项式回归</h1><p>$$h(\theta) = \theta_0 + \theta_1x + \theta_2x^2 + \dots + \theta_nx^n$$</p>
<p>可用$x_2 = x_2^2,x_3 = x_3^3\dots$ 将模型转化为线性回归模型</p>
<ul>
<li>注：这种方法要注意对变量进行特征缩放</li>
</ul>
<h1 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h1><p>不通过迭代，直接求出$\theta$的最优值</p>
<p>假设我们的训练集特征矩阵为$X$(包含了$x_0 = 1$)并且我们的训练集结果为向量$y$，则利用正规方程解出向量</p>
<p>$$\theta = (X^TX)^{-1}X^Ty$$</p>
<p>其中$X$为$m *(n+1)$维,$y$为$m$列</p>
<p>例</p>
<p>$$\begin{aligned}<br>&amp;\begin{array}{c|c|c|c|c|c}<br>x_{0} &amp; x_{1} &amp; x_{2} &amp; x_{3} &amp; x_{4} &amp; y \<br>\hline 1 &amp; 2104 &amp; 5 &amp; 1 &amp; 45 &amp; 460 \<br>1 &amp; 1416 &amp; 3 &amp; 2 &amp; 40 &amp; 232 \<br>1 &amp; 1534 &amp; 3 &amp; 2 &amp; 30 &amp; 315 \<br>1 &amp; 852 &amp; 2 &amp; 1 &amp; 36 &amp; 178<br>\end{array}\<br>则X可写成\\<br>&amp;X=\left[\begin{array}{ccccc}<br>1 &amp; 2104 &amp; 5 &amp; 1 &amp; 45 \<br>1 &amp; 1416 &amp; 3 &amp; 2 &amp; 40 \<br>1 &amp; 1534 &amp; 3 &amp; 2 &amp; 30 \<br>1 &amp; 852 &amp; 2 &amp; 1 &amp; 36<br>\end{array}\right]<br>\end{aligned}$$</p>
<p>此方法不需要提前对变量进行特征缩放，且不需要学习率$\alpha$</p>
<table>
<thead>
<tr>
<th>梯度下降</th>
<th>正规方程</th>
</tr>
</thead>
<tbody><tr>
<td>需要选择学习率</td>
<td>不需要</td>
</tr>
<tr>
<td>需要多次迭代</td>
<td>一次运算得出</td>
</tr>
<tr>
<td>当特征数量n大时也能较好适用</td>
<td>需要计算$(X^TX)^{-1}$如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为$O(n^3)$，通常来说当小于10000 时还是可以接受的</td>
</tr>
<tr>
<td>适用于各种类型的模型</td>
<td>只适用于线性模型，不适合逻辑回归模型等其他模型</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ex1-%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ex1-%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">机器学习/ex1-单变量线性回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-10 21:53:17 / Modified: 21:55:46" itemprop="dateCreated datePublished" datetime="2020-08-10T21:53:17+08:00">2020-08-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A/" itemprop="url" rel="index"><span itemprop="name">机器学习作业</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="单变量线性回归"><a href="#单变量线性回归" class="headerlink" title="单变量线性回归"></a>单变量线性回归</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>

<h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读入文件</span></span><br><span class="line">file = <span class="string">'ex1data1.txt'</span></span><br><span class="line">data = pd.read_csv(file, names = [<span class="string">'population'</span>,<span class="string">'profit'</span>])</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>population</th>
      <th>profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.1101</td>
      <td>17.5920</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.5277</td>
      <td>9.1302</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8.5186</td>
      <td>13.6620</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.0032</td>
      <td>11.8540</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.8598</td>
      <td>6.8233</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.shape</span><br></pre></td></tr></table></figure>




<pre><code>(97, 2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">data.plot(kind=<span class="string">'scatter'</span>, x=<span class="string">'population'</span>, y=<span class="string">'profit'</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x200ae1906d8&gt;</code></pre><p><img src="/2020/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ex1-%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_5_1.png" alt="png"></p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>我们希望下列函数最小<br>$$J\left(\theta\right)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}$$</p>
<p>其中<br>$$h_\theta(x) = x\theta^T = \theta_0 + \theta_1x_1$$</p>
<p>$ x = [1,population]$</p>
<p>$\theta = [\theta_0 ,\ \theta_1] $</p>
<p>由梯度下降算法，我们不断更新$\theta_j$  (注意要同时更新所有参数)<br>$$\theta_j = \theta_j - \alpha\frac{1}{m}\sum_{i = 1}^m(h_\theta(x^{(i)})-(y^{(i)}))x_j^{(i)}$$</p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ComputerCost</span><span class="params">(x,y,theta)</span>:</span></span><br><span class="line">    inner = np.power(((x * theta.T ) - y ),<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> np.sum(inner)/(<span class="number">2</span> * len(x))</span><br></pre></td></tr></table></figure>

<h2 id="变量处理"><a href="#变量处理" class="headerlink" title="变量处理"></a>变量处理</h2><ul>
<li>We store each example as a row in the the X<br>matrix in Octave/MATLAB. To take into account the intercept term ($\theta_0$),<br>we add an additional first column to X and set it to all ones. This allows<br>us to treat $\theta_0$ as simply another ‘feature’.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.insert(<span class="number">0</span>, <span class="string">'Ones'</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Ones</th>
      <th>population</th>
      <th>profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>6.1101</td>
      <td>17.5920</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>5.5277</td>
      <td>9.1302</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>8.5186</td>
      <td>13.6620</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>7.0032</td>
      <td>11.8540</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>5.8598</td>
      <td>6.8233</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列数</span></span><br><span class="line">cols = data.shape[<span class="number">1</span>]<span class="comment"># = 2</span></span><br><span class="line"><span class="comment">#自变量</span></span><br><span class="line">x = data.iloc[:,<span class="number">0</span>:cols<span class="number">-1</span>]</span><br><span class="line">x.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Ones</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>6.1101</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>5.5277</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>8.5186</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>7.0032</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>5.8598</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因变量</span></span><br><span class="line">y = data.iloc[:,cols<span class="number">-1</span>:cols]</span><br><span class="line">y.head()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>profit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17.5920</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9.1302</td>
    </tr>
    <tr>
      <th>2</th>
      <td>13.6620</td>
    </tr>
    <tr>
      <th>3</th>
      <td>11.8540</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.8233</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="格式转换"><a href="#格式转换" class="headerlink" title="格式转换"></a>格式转换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.matrix(x.values)</span><br><span class="line">y = np.matrix(y.values)</span><br><span class="line">theta = np.matrix([<span class="number">0</span>,<span class="number">0</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(x.shape,theta.shape,y.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(97, 2) (1, 2) (97, 1)</code></pre><h2 id="计算代价函数"><a href="#计算代价函数" class="headerlink" title="计算代价函数"></a>计算代价函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ComputerCost(x,y,theta)</span><br></pre></td></tr></table></figure>




<pre><code>32.072733877455676</code></pre><h2 id="batch-gradient-decent"><a href="#batch-gradient-decent" class="headerlink" title="batch gradient decent"></a>batch gradient decent</h2><p>$$\theta:=\theta-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x^{(i)}\right) $$</p>
<p>$$\theta:=\theta-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(x\theta^T - y \right)\cdot x\right) $$</p>
<p>在x中加入一列1，用来用向量化的方式解决$\theta_0$的问题</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span><span class="params">(x, y, theta, alpha, epoch)</span>:</span></span><br><span class="line">    temp = np.matrix(np.zeros(theta.shape))</span><br><span class="line">    cost = np.zeros(epoch)<span class="comment">#存储每次循环的误差</span></span><br><span class="line">    m = x.shape[<span class="number">0</span>]<span class="comment">#样本数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        <span class="comment"># 梯度下降</span></span><br><span class="line">        temp = theta - (alpha/m) * (x * theta.T - y).T * x</span><br><span class="line">        theta = temp</span><br><span class="line">        cost[i] = ComputerCost(x,y,theta)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> theta,cost</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">1000</span></span><br></pre></td></tr></table></figure>

<h2 id="回归结果"><a href="#回归结果" class="headerlink" title="回归结果"></a>回归结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final_theta, cost = gradientDescent(x,y,theta,alpha,epoch)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final_theta</span><br></pre></td></tr></table></figure>




<pre><code>matrix([[-3.24140214,  1.1272942 ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cost[::<span class="number">100</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([6.73719046, 5.47636282, 5.17363455, 4.96260649, 4.81550149,
       4.71295645, 4.6414736 , 4.5916438 , 4.55690808, 4.53269424])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ComputerCost(x,y,final_theta)</span><br></pre></td></tr></table></figure>




<pre><code>4.515955503078912</code></pre><h2 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(data.population.min(), data.population.max(), <span class="number">100</span>)  <span class="comment"># 横坐标</span></span><br><span class="line">f = final_theta[<span class="number">0</span>, <span class="number">0</span>] + (final_theta[<span class="number">0</span>, <span class="number">1</span>] * x)  <span class="comment"># 纵坐标，利润</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(x, f, <span class="string">'r'</span>, label=<span class="string">'Prediction'</span>)</span><br><span class="line">ax.scatter(data[<span class="string">'population'</span>], data.profit, label=<span class="string">'Traning Data'</span>)</span><br><span class="line">ax.legend(loc=<span class="number">2</span>)  <span class="comment"># 2表示在左上角</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Population'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Profit'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Predicted Profit vs. Population Size'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ex1-%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_34_0.png" alt="png"></p>
<ul>
<li>代价函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(np.arange(epoch), cost, <span class="string">'r'</span>)  <span class="comment"># np.arange()返回等差数组</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Iterations'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Cost'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Error vs. Training Epoch'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/2020/08/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ex1-%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/output_36_0.png" alt="png"></p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 读入文件</span></span><br><span class="line">file = <span class="string">'ex1data1.txt'</span></span><br><span class="line">data = pd.read_csv(file, names = [<span class="string">'population'</span>,<span class="string">'profit'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">data.plot(kind=<span class="string">'scatter'</span>, x=<span class="string">'population'</span>, y=<span class="string">'profit'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代价函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ComputerCost</span><span class="params">(x,y,theta)</span>:</span></span><br><span class="line">    inner = np.power(((x * theta.T ) - y ),<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> np.sum(inner)/(<span class="number">2</span> * len(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向量化预处理x数组</span></span><br><span class="line">data.insert(<span class="number">0</span>, <span class="string">'Ones'</span>,<span class="number">1</span>)</span><br><span class="line">cols = data.shape[<span class="number">1</span>]<span class="comment"># = 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取自变量</span></span><br><span class="line">x = data.iloc[:,<span class="number">0</span>:cols<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取因变量</span></span><br><span class="line">y = data.iloc[:,cols<span class="number">-1</span>:cols]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 格式转换</span></span><br><span class="line">x = np.matrix(x.values)</span><br><span class="line">y = np.matrix(y.values)</span><br><span class="line">theta = np.matrix([<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">ComputerCost(x,y,theta)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span><span class="params">(x, y, theta, alpha, epoch)</span>:</span></span><br><span class="line">    temp = np.matrix(np.zeros(theta.shape))</span><br><span class="line">    cost = np.zeros(epoch)<span class="comment">#存储每次循环的误差</span></span><br><span class="line">    m = x.shape[<span class="number">0</span>]<span class="comment">#样本数量</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(epoch):</span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        temp = theta - (alpha/m) * (x * theta.T - y).T * x</span><br><span class="line">        theta = temp</span><br><span class="line">        cost[i] = ComputerCost(x,y,theta)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> theta,cost</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 回归结果</span></span><br><span class="line">final_theta, cost = gradientDescent(x,y,theta,alpha,epoch)</span><br><span class="line">ComputerCost(x,y,final_theta)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回归图像</span></span><br><span class="line">x = np.linspace(data.population.min(), data.population.max(), <span class="number">100</span>)  <span class="comment"># 横坐标</span></span><br><span class="line">f = final_theta[<span class="number">0</span>, <span class="number">0</span>] + (final_theta[<span class="number">0</span>, <span class="number">1</span>] * x)  <span class="comment"># 纵坐标，利润</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(x, f, <span class="string">'r'</span>, label=<span class="string">'Prediction'</span>)</span><br><span class="line">ax.scatter(data[<span class="string">'population'</span>], data.profit, label=<span class="string">'Traning Data'</span>)</span><br><span class="line">ax.legend(loc=<span class="number">2</span>)  <span class="comment"># 2表示在左上角</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Population'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Profit'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Predicted Profit vs. Population Size'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 误差图像</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(np.arange(epoch), cost, <span class="string">'r'</span>)  <span class="comment"># np.arange()返回等差数组</span></span><br><span class="line">ax.set_xlabel(<span class="string">'Iterations'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'Cost'</span>)</span><br><span class="line">ax.set_title(<span class="string">'Error vs. Training Epoch'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/08/Python/Numpy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/08/Python/Numpy/" class="post-title-link" itemprop="url">Python/Numpy</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-08 15:03:28" itemprop="dateCreated datePublished" datetime="2020-08-08T15:03:28+08:00">2020-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-14 20:56:42" itemprop="dateModified" datetime="2020-09-14T20:56:42+08:00">2020-09-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.__version__</span><br></pre></td></tr></table></figure>




<pre><code>&apos;1.15.1&apos;</code></pre><h1 id="python-中的数据类型"><a href="#python-中的数据类型" class="headerlink" title="python 中的数据类型"></a>python 中的数据类型</h1><ul>
<li>动态类型</li>
</ul>
<p>每一个 Python 对象都是一个聪明的伪 C 语言结构体，该结构体不仅包含其值，还有其他信息。例如，当我们在 Python 中定义一个整型，例如 x = 10000 时，x 并不是一个“原生”整型，而是一个指针，指向一个 C 语言的复合结构体，结构体里包含了一些值。</p>
<p>Python 3.4 中的一个整型实际上包括 4 个部分。</p>
<ol>
<li>ob_refcnt 是一个引用计数，它帮助 Python 默默地处理内存的分配和回收。</li>
<li>ob_type 将变量的类型编码。</li>
<li>ob_size 指定接下来的数据成员的大小。</li>
<li>ob_digit 包含我们希望 Python 变量表示的实际整型值。</li>
</ol>
<p>Python 的整型其实是一个指针，指向包含这个 Python 对象所有信息的某个内存位置，其中包括可以转换成整型的字节。</p>
<h2 id="列表与数组"><a href="#列表与数组" class="headerlink" title="列表与数组"></a>列表与数组</h2><p>数组基本上包含一个指向连续数据块的指针。Python 列表包含一个指向指针块的指针，这其中的每一个指针对应一个完整的 Python 对象。</p>
<h1 id="创建NumPy数组"><a href="#创建NumPy数组" class="headerlink" title="创建NumPy数组"></a>创建NumPy数组</h1><h2 id="从列表创建时数组"><a href="#从列表创建时数组" class="headerlink" title="从列表创建时数组"></a>从列表创建时数组</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.array([<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 4, 2, 5, 3])</code></pre><ul>
<li>numpy的数组必须包含同一数据类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.array([<span class="number">1</span>,<span class="number">3.14</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>])</span><br></pre></td></tr></table></figure>




<pre><code>array([1.  , 3.14, 2.  , 3.  , 5.  ])</code></pre><ul>
<li>设置数据类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], dtype=<span class="string">'float32'</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([1., 2., 3., 4.], dtype=float32)</code></pre><ul>
<li>多维数组</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.array([range(i, i+ <span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>array([[2, 3, 4],
       [4, 5, 6],
       [6, 7, 8]])</code></pre><h2 id="从头创建数组"><a href="#从头创建数组" class="headerlink" title="从头创建数组"></a>从头创建数组</h2><ol>
<li>zeros, ones, full<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个长度为10的数组，数组的值都是0</span></span><br><span class="line">np.zeros(<span class="number">10</span>, dtype=int)</span><br></pre></td></tr></table></figure>




</li>
</ol>
<pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个3×5的浮点型数组，数组的值都是1</span></span><br><span class="line">np.ones((<span class="number">3</span>, <span class="number">5</span>), dtype=float)</span><br></pre></td></tr></table></figure>




<pre><code>array([[1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.],
       [1., 1., 1., 1., 1.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个3×5的浮点型数组，数组的值都是3.14</span></span><br><span class="line">np.full((<span class="number">3</span>, <span class="number">5</span>), <span class="number">3.14</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([[3.14, 3.14, 3.14, 3.14, 3.14],
       [3.14, 3.14, 3.14, 3.14, 3.14],
       [3.14, 3.14, 3.14, 3.14, 3.14]])</code></pre><ol start="2">
<li>生成函数</li>
</ol>
<ul>
<li>arange<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个线性序列数组</span></span><br><span class="line"><span class="comment"># 从0开始，到20结束，步长为2</span></span><br><span class="line"><span class="comment"># （它和内置的range()函数类似）</span></span><br><span class="line">np.arange(<span class="number">0</span>, <span class="number">20</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>




</li>
</ul>
<pre><code>array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])</code></pre><ul>
<li>linspace<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个5个元素的数组，这5个数均匀地分配到0~1</span></span><br><span class="line">np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>




</li>
</ul>
<pre><code>array([0.  , 0.25, 0.5 , 0.75, 1.  ])</code></pre><ul>
<li>random</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个3×3的、在0~1均匀分布的随机数组成的数组</span></span><br><span class="line">np.random.random((<span class="number">3</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.49386296, 0.03091395, 0.63736667],
       [0.26917584, 0.75625911, 0.63322542],
       [0.49350228, 0.7378019 , 0.05978184]])</code></pre><ul>
<li>正态分布</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个3×3的、均值为0、标准差为1的</span></span><br><span class="line"><span class="comment"># 正态分布的随机数数组</span></span><br><span class="line">np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">3</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[-1.93643725,  0.77082268,  0.02398928],
       [ 0.19744958, -0.11037934, -2.29430912],
       [-0.10966178, -1.58837058,  0.04196946]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个3×3的、[0, 10)区间的随机整型数组</span></span><br><span class="line">np.random.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">3</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[8, 1, 2],
       [8, 9, 5],
       [2, 2, 7]])</code></pre><ul>
<li>矩阵<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个3×3的单位矩阵</span></span><br><span class="line">np.eye(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>




</li>
</ul>
<pre><code>array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个由3个整型数组成的未初始化的数组</span></span><br><span class="line"><span class="comment"># 数组的值是内存空间中的任意值</span></span><br><span class="line">np.empty(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([1., 1., 1.])</code></pre><h1 id="NumPy-数组基础"><a href="#NumPy-数组基础" class="headerlink" title="NumPy 数组基础"></a>NumPy 数组基础</h1><ul>
<li>ndim: 数组的维度</li>
<li>shape： 数组每个维度的大小</li>
<li>size: 数组的总大小</li>
<li>dtype： 数据类型</li>
<li>itemsize： 每个数组元素字节的大小</li>
<li>nbytes：数组总字节大小<br>一般来说，可以认为 nbytes 跟 itemsize 和 size 的乘积大小相等</li>
</ul>
<p>调用方式：a.shape 即可</p>
<h2 id="多维数组切片"><a href="#多维数组切片" class="headerlink" title="多维数组切片"></a>多维数组切片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">10</span>, size=(<span class="number">3</span>, <span class="number">4</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>array([[8, 1, 0, 2],
       [2, 1, 8, 5],
       [8, 9, 7, 9]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:<span class="number">2</span>,:<span class="number">3</span>] <span class="comment"># 两行，三列</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[8, 1, 0],
       [2, 1, 8]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:<span class="number">3</span>,::<span class="number">2</span>] <span class="comment"># 所有行，每隔一列</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[8, 0],
       [2, 8],
       [8, 7]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[::<span class="number">-1</span>,::<span class="number">-1</span>] <span class="comment"># 逆序</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[9, 7, 9, 8],
       [5, 8, 1, 2],
       [2, 0, 1, 8]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:,<span class="number">0</span>] <span class="comment"># 第一列</span></span><br></pre></td></tr></table></figure>




<pre><code>array([8, 2, 8])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[<span class="number">0</span>,:] <span class="comment"># 第一行  等价于x[0]</span></span><br></pre></td></tr></table></figure>




<pre><code>array([8, 1, 0, 2])</code></pre><ul>
<li>注： 数组切片返回的是数组数据的视图，而不是数值数据的副本。修改这个子数组，将会看到原始数组也被修改</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_sub = x[:<span class="number">2</span>,:<span class="number">2</span>]</span><br><span class="line">x_sub[<span class="number">0</span>,<span class="number">0</span>] = <span class="number">99</span></span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<pre><code>[[99  1  0  2]
 [ 2  1  8  5]
 [ 8  9  7  9]]</code></pre><p>当我们想得到副本而不是视图时，可以使用copy函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_sub_copy = x[:<span class="number">2</span>,:<span class="number">2</span>].copy()</span><br></pre></td></tr></table></figure>

<h2 id="数组的变形"><a href="#数组的变形" class="headerlink" title="数组的变形"></a>数组的变形</h2><p>关键:原始数组的大小必须和变形后数组的大小一致。如果满足这个条件，reshape 方法将会用到原始数组的一个非副本视图。但实际情况是，在非连续的数据缓存的情况下，返回非副本视图往往不可能实现。</p>
<p>另外一个常见的变形模式是将一个一维数组转变为二维的行或列的矩阵。你也可以通过 reshape 方法来实现，或者更简单地在一个切片操作中利用 newaxis 关键字：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grid = np.arange(<span class="number">1</span>, <span class="number">10</span>).reshape((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">print(grid)</span><br></pre></td></tr></table></figure>

<pre><code>[[1 2 3]
 [4 5 6]
 [7 8 9]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">x.reshape((<span class="number">1</span>,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 2, 3]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[np.newaxis,:]<span class="comment"># 获得行向量</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 2, 3]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.reshape((<span class="number">3</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>




<pre><code>array([[1],
       [2],
       [3]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:,np.newaxis]<span class="comment"># 获得列向量</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[1],
       [2],
       [3]])</code></pre><h2 id="数组的拼接和分裂"><a href="#数组的拼接和分裂" class="headerlink" title="数组的拼接和分裂"></a>数组的拼接和分裂</h2><h3 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h3><ul>
<li>np.concatenate</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">y = np.array([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">np.concatenate([x, y])</span><br><span class="line">z = [<span class="number">99</span>, <span class="number">99</span>, <span class="number">99</span>]</span><br><span class="line">print(np.concatenate([x, y, z]))</span><br></pre></td></tr></table></figure>

<pre><code>[ 1  2  3  3  2  1 99 99 99]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二维数组</span></span><br><span class="line">grid = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">                 [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="comment"># 沿着第一个轴拼接</span></span><br><span class="line">np.concatenate([grid, grid])</span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 2, 3],
       [4, 5, 6],
       [1, 2, 3],
       [4, 5, 6]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 沿着第二个轴拼接（从0开始索引）</span></span><br><span class="line">np.concatenate([grid, grid], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 2, 3, 1, 2, 3],
       [4, 5, 6, 4, 5, 6]])</code></pre><ul>
<li><p>注：</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    &#96;&#96;&#96;axis &#x3D; 1&#96;&#96;&#96; 横轴</span><br><span class="line">* np.vstack(垂直栈)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">x &#x3D; np.array([1, 2, 3])</span><br><span class="line">grid &#x3D; np.array([[9, 8, 7],</span><br><span class="line">                 [6, 5, 4]])</span><br><span class="line"></span><br><span class="line"># 垂直栈数组</span><br><span class="line">np.vstack([x, grid])</span><br></pre></td></tr></table></figure>




</li>
</ul>
<pre><code>array([[1, 2, 3],
       [9, 8, 7],
       [6, 5, 4]])</code></pre><ul>
<li>水平栈</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = np.array([[<span class="number">99</span>],</span><br><span class="line">              [<span class="number">99</span>]])</span><br><span class="line">np.hstack([grid, y])</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 9,  8,  7, 99],
       [ 6,  5,  4, 99]])</code></pre><p>与之类似，np.dstack 将沿着第三个维度拼接数组。</p>
<h3 id="分裂"><a href="#分裂" class="headerlink" title="分裂"></a>分裂</h3><ul>
<li>np.split</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">99</span>, <span class="number">99</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">x1, x2, x3 = np.split(x, [<span class="number">3</span>, <span class="number">5</span>])<span class="comment">#索引列表记录的是分裂点位置</span></span><br><span class="line"><span class="comment">#N 分裂点会得到 N + 1 个子数组</span></span><br><span class="line">print(x1, x2, x3)</span><br></pre></td></tr></table></figure>

<pre><code>[1 2 3] [99 99] [3 2 1]</code></pre><ul>
<li>np.vsplit</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">grid = np.arange(<span class="number">16</span>).reshape((<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">upper, lower = np.vsplit(grid, [<span class="number">2</span>])</span><br><span class="line">print(upper)</span><br><span class="line">print(lower)</span><br></pre></td></tr></table></figure>

<pre><code>[[0 1 2 3]
 [4 5 6 7]]
[[ 8  9 10 11]
 [12 13 14 15]]</code></pre><ul>
<li>np.hsplit</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">left, right = np.hsplit(grid, [<span class="number">2</span>])</span><br><span class="line">print(left)</span><br><span class="line">print(right)</span><br></pre></td></tr></table></figure>

<pre><code>[[ 0  1]
 [ 4  5]
 [ 8  9]
 [12 13]]
[[ 2  3]
 [ 6  7]
 [10 11]
 [14 15]]</code></pre><p>同样，np.dsplit 将数组沿着第三个维度分裂。</p>
<h1 id="Numpy数组的计算：通用函数"><a href="#Numpy数组的计算：通用函数" class="headerlink" title="Numpy数组的计算：通用函数"></a>Numpy数组的计算：通用函数</h1><p>使 NumPy 变快的关键是利用向量化操作，通常在 NumPy 的通用函数（ufunc）中实现。</p>
<h2 id="数组的运算"><a href="#数组的运算" class="headerlink" title="数组的运算"></a>数组的运算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(<span class="number">4</span>)</span><br><span class="line"><span class="number">2</span>**x</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 2, 4, 8], dtype=int32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abs(-x)</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 1, 2, 3])</code></pre><ul>
<li>当处理复数时，绝对值返回的是该复数的模（magnitude）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三角函数</span></span><br><span class="line">theta = np.linspace(<span class="number">0</span>, np.pi, <span class="number">3</span>)</span><br><span class="line">print(<span class="string">"theta      = "</span>, theta)</span><br><span class="line">print(<span class="string">"sin(theta) = "</span>, np.sin(theta))</span><br><span class="line">print(<span class="string">"cos(theta) = "</span>, np.cos(theta))</span><br><span class="line">print(<span class="string">"arctan(theta) = "</span>, np.arctan(theta))</span><br></pre></td></tr></table></figure>

<pre><code>theta      =  [0.         1.57079633 3.14159265]
sin(theta) =  [0.0000000e+00 1.0000000e+00 1.2246468e-16]
cos(theta) =  [ 1.000000e+00  6.123234e-17 -1.000000e+00]
arctan(theta) =  [0.         1.00388482 1.26262726]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指数对数</span></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">print(<span class="string">"x     ="</span>, x)</span><br><span class="line">print(<span class="string">"e^x   ="</span>, np.exp(x))</span><br><span class="line">print(<span class="string">"2^x   ="</span>, np.exp2(x))</span><br><span class="line">print(<span class="string">"3^x   ="</span>, np.power(<span class="number">3</span>, x))</span><br><span class="line">print(<span class="string">"x        ="</span>, x)</span><br><span class="line">print(<span class="string">"ln(x)    ="</span>, np.log(x))</span><br><span class="line">print(<span class="string">"log2(x)  ="</span>, np.log2(x))</span><br><span class="line">print(<span class="string">"log10(x) ="</span>, np.log10(x))</span><br></pre></td></tr></table></figure>

<pre><code>x     = [1, 2, 3]
e^x   = [ 2.71828183  7.3890561  20.08553692]
2^x   = [2. 4. 8.]
3^x   = [ 3  9 27]
x        = [1, 2, 3]
ln(x)    = [0.         0.69314718 1.09861229]
log2(x)  = [0.        1.        1.5849625]
log10(x) = [0.         0.30103    0.47712125]</code></pre><p>对于非常小的输入值可以保持较好的精度：np.expm1(x))，np.log1p(x))</p>
<h2 id="高级的通用函数特性"><a href="#高级的通用函数特性" class="headerlink" title="高级的通用函数特性"></a>高级的通用函数特性</h2><h3 id="指定输出"><a href="#指定输出" class="headerlink" title="指定输出"></a>指定输出</h3><p>在进行大量运算时，有时候指定一个用于存放运算结果的数组是非常有用的。不同于创建临时数组，你可以用这个特性将计算结果直接写入到你期望的存储位置。所有的通用函数都可以通过 out 参数来指定计算结果的存放位置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(<span class="number">5</span>)</span><br><span class="line">y = np.empty(<span class="number">5</span>)</span><br><span class="line">np.multiply(x, <span class="number">10</span>, out=y)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>

<pre><code>[ 0. 10. 20. 30. 40.]</code></pre><p>将计算结果写入指定数组的每隔一个元素的位置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y = np.zeros(<span class="number">10</span>)</span><br><span class="line">z = np.zeros(<span class="number">10</span>)</span><br><span class="line">np.power(<span class="number">2</span>, x, out=y[::<span class="number">2</span>])</span><br><span class="line">z[::<span class="number">2</span>] = <span class="number">2</span> ** x</span><br><span class="line">print(y)</span><br><span class="line">print(z)</span><br></pre></td></tr></table></figure>

<pre><code>[ 1.  0.  2.  0.  4.  0.  8.  0. 16.  0.]
[ 1.  0.  2.  0.  4.  0.  8.  0. 16.  0.]</code></pre><p>如果这里写的是 <code>z[::2] = 2 ** x</code>，那么结果将是创建一个临时数组，该数组存放的是 2 ** x 的结果，并且接下来会将这些值复制到 z 数组中。对于上述例子中比较小的计算量来说，这两种方式的差别并不大。但是对于较大的数组，通过慎重使用 out 参数将能够有效节约内存。</p>
<h3 id="聚合"><a href="#聚合" class="headerlink" title="聚合"></a>聚合</h3><ul>
<li>reduce方法：对给定的元素和操作重复执行，直至得到单个的结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line">np.add.reduce(x)</span><br></pre></td></tr></table></figure>




<pre><code>15</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.add.accumulate(x)<span class="comment">#储存中间变量</span></span><br></pre></td></tr></table></figure>




<pre><code>array([ 1,  3,  6, 10, 15], dtype=int32)</code></pre><h3 id="外积"><a href="#外积" class="headerlink" title="外积"></a>外积</h3><p>用 outer 方法获得两个不同输入数组所有元素对的函数运算结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.arange(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line">np.multiply.outer(x,x)</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 1,  2,  3,  4,  5],
       [ 2,  4,  6,  8, 10],
       [ 3,  6,  9, 12, 15],
       [ 4,  8, 12, 16, 20],
       [ 5, 10, 15, 20, 25]])</code></pre><h1 id="聚合：最小值、最大值和其他值"><a href="#聚合：最小值、最大值和其他值" class="headerlink" title="聚合：最小值、最大值和其他值"></a>聚合：最小值、最大值和其他值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">big_array = np.random.rand(<span class="number">1000000</span>)</span><br><span class="line">np.min(big_array)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">print(big_array.min(), big_array.max(), big_array.sum())</span><br></pre></td></tr></table></figure>

<pre><code>4.781662075181714e-07 0.9999993314903649 500159.4600340406</code></pre><ul>
<li>注：np.min(),np.sum() 往往比python中的min(),sum() 更快</li>
</ul>
<h2 id="多维度聚合"><a href="#多维度聚合" class="headerlink" title="多维度聚合"></a>多维度聚合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">M = np.random.random((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">M.sum()</span><br><span class="line">print(M)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.73186364 0.81219213 0.99000414 0.72825554]
 [0.94816677 0.82588605 0.24290017 0.8000844 ]
 [0.95091721 0.49839234 0.32700048 0.12345992]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">M.min(axis = <span class="number">0</span>) <span class="comment"># axis = 0每列最小值 axis=1 行最小值</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0.73186364, 0.49839234, 0.24290017, 0.12345992])</code></pre><ul>
<li>注：axis 关键字指定的是数组将会被折叠的维度，而不是将要返回的维度。因此指定 axis=0 意味着第一个轴将要被折叠——对于二维数组，这意味着每一列的值都将被聚合。</li>
</ul>
<table>
<thead>
<tr>
<th>函数名称</th>
<th>NaN安全版</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>np.sum</td>
<td>np.nansum</td>
<td>计算元素的和</td>
</tr>
<tr>
<td>np.prod</td>
<td>np.nanprod</td>
<td>计算元素的积</td>
</tr>
<tr>
<td>np.mean</td>
<td>np.nanmean</td>
<td>计算元素的平均值</td>
</tr>
<tr>
<td>np.std</td>
<td>np.nanstd</td>
<td>计算元素的标准差</td>
</tr>
<tr>
<td>np.var</td>
<td>np.nanvar</td>
<td>计算元素的方差</td>
</tr>
<tr>
<td>np.min</td>
<td>np.nanmin</td>
<td>找出最小值</td>
</tr>
<tr>
<td>np.max</td>
<td>np.nanmax</td>
<td>找出最大值</td>
</tr>
<tr>
<td>np.argmin</td>
<td>np.nanargmin</td>
<td>找出最小值的索引</td>
</tr>
<tr>
<td>np.argmax</td>
<td>np.nanargmax</td>
<td>找出最大值的索引</td>
</tr>
<tr>
<td>np.median</td>
<td>np.nanmedian</td>
<td>计算元素的中位数</td>
</tr>
<tr>
<td>np.percentile</td>
<td>np.nanpercentile</td>
<td>计算基于元素排序的统计值</td>
</tr>
<tr>
<td>np.any</td>
<td>N/A</td>
<td>验证是否存在元素为真</td>
</tr>
<tr>
<td>np.all</td>
<td>N/A</td>
<td>验证所有元素是否为真</td>
</tr>
</tbody></table>
<h1 id="广播"><a href="#广播" class="headerlink" title="广播"></a>广播</h1><p>用于不同大小数组的二元通用函数（加、减、乘等）的一组规则。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">a + <span class="number">5</span></span><br></pre></td></tr></table></figure>




<pre><code>array([5, 6, 7])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">M = np.ones((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">M</span><br></pre></td></tr></table></figure>




<pre><code>array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">M + a</span><br></pre></td></tr></table></figure>




<pre><code>array([[1., 2., 3.],
       [1., 2., 3.],
       [1., 2., 3.]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">3</span>)</span><br><span class="line">b = np.arange(<span class="number">3</span>)[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">print(a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>

<pre><code>[0 1 2]
[[0]
 [1]
 [2]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a + b</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 1, 2],
       [1, 2, 3],
       [2, 3, 4]])</code></pre><ul>
<li>先进行相应的扩展再计算</li>
</ul>
<ol>
<li><p>如果两个数组的维度数不相同，那么小维度数组的形状将会在最左边补 1。</p>
</li>
<li><p>如果两个数组的形状在任何一个维度上都不匹配，那么数组的形状会沿着维度为 1 的维度扩展以匹配另外一个数组的形状。</p>
</li>
<li><p>如果两个数组的形状在任何一个维度上都不匹配并且没有任何一个维度等于 1，那么会引发异常。</p>
</li>
</ol>
<ul>
<li>例1</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">M = np.ones((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">a = np.arange(<span class="number">3</span>)</span><br><span class="line">a + M</span><br></pre></td></tr></table></figure>




<pre><code>array([[1., 2., 3.],
       [1., 2., 3.]])</code></pre><h1 id="比较、掩码和布尔逻辑"><a href="#比较、掩码和布尔逻辑" class="headerlink" title="比较、掩码和布尔逻辑"></a>比较、掩码和布尔逻辑</h1><h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">x &lt; <span class="number">3</span></span><br></pre></td></tr></table></figure>




<pre><code>array([ True,  True, False, False, False])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">2</span> * x) == (x ** <span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([False,  True, False, False, False])</code></pre><table>
<thead>
<tr>
<th>运算符</th>
<th>对应的通用函数</th>
</tr>
</thead>
<tbody><tr>
<td>==</td>
<td>np.equal</td>
</tr>
<tr>
<td>!=</td>
<td>np.not_equal</td>
</tr>
<tr>
<td>&lt;</td>
<td>np.less</td>
</tr>
<tr>
<td>&lt;=</td>
<td>np.less_equal</td>
</tr>
<tr>
<td>&gt;</td>
<td>np.greater</td>
</tr>
<tr>
<td>&gt;=</td>
<td>np.greater_equal</td>
</tr>
</tbody></table>
<h2 id="操纵布尔数组"><a href="#操纵布尔数组" class="headerlink" title="操纵布尔数组"></a>操纵布尔数组</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rng = np.random.RandomState(<span class="number">0</span>)</span><br><span class="line">x = rng.randint(<span class="number">10</span>, size=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>array([[5, 0, 3, 3],
       [7, 9, 3, 5],
       [2, 4, 7, 6]])</code></pre><ul>
<li>统计布尔数组中<code>true</code>纪录的个数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 有多少值小于6？</span></span><br><span class="line">np.count_nonzero(x &lt; <span class="number">6</span>)</span><br></pre></td></tr></table></figure>




<pre><code>8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.sum(x &lt; <span class="number">6</span>)</span><br></pre></td></tr></table></figure>




<pre><code>8</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每行有多少值小于6？</span></span><br><span class="line">np.sum(x &lt; <span class="number">6</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([4, 2, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有没有值大于8？</span></span><br><span class="line">np.any(x &gt; <span class="number">8</span>, axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([False,  True, False])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.all(x == <span class="number">6</span>)</span><br></pre></td></tr></table></figure>




<pre><code>False</code></pre><ul>
<li>确保在以上的示例中用的都是 np.sum()、np.any() 和 np.all() 函数。</li>
</ul>
<h2 id="布尔运算符"><a href="#布尔运算符" class="headerlink" title="布尔运算符"></a>布尔运算符</h2><table>
<thead>
<tr>
<th>运算符</th>
<th>对应通用函数</th>
</tr>
</thead>
<tbody><tr>
<td>&amp;</td>
<td>np.bitwise_and</td>
</tr>
<tr>
<td>|</td>
<td>np.bitwise_or</td>
</tr>
<tr>
<td>^</td>
<td>np.bitwise_xor</td>
</tr>
<tr>
<td>~</td>
<td>np.bitwise_not</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.sum((x &gt; <span class="number">4</span>) &amp; (x&lt; <span class="number">7</span>))</span><br></pre></td></tr></table></figure>




<pre><code>3</code></pre><h2 id="将布尔数组作为掩码"><a href="#将布尔数组作为掩码" class="headerlink" title="将布尔数组作为掩码"></a>将布尔数组作为掩码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>array([[5, 0, 3, 3],
       [7, 9, 3, 5],
       [2, 4, 7, 6]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[x &lt; <span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([0, 3, 3, 3, 2, 4])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.median(x[x &lt; <span class="number">5</span>])</span><br></pre></td></tr></table></figure>




<pre><code>3.0</code></pre><h1 id="花哨的索引（fancy-indexing）"><a href="#花哨的索引（fancy-indexing）" class="headerlink" title="花哨的索引（fancy indexing）"></a>花哨的索引（fancy indexing）</h1><p>花哨的索引和前面那些简单的索引非常类似，但是传递的是索引数组，而不是单个标量。花哨的索引让我们能够快速获得并修改复杂的数组值的子数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rand = np.random.RandomState(<span class="number">42</span>)</span><br><span class="line">x = rand.randint(<span class="number">100</span>, size=<span class="number">10</span>)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<pre><code>[51 92 14 71 60 20 82 86 74 74]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ind = [<span class="number">3</span>, <span class="number">7</span>, <span class="number">4</span>]</span><br><span class="line">x[ind]</span><br></pre></td></tr></table></figure>




<pre><code>array([71, 86, 60])</code></pre><p>利用花哨的索引，结果的形状与索引数组的形状一致，而不是与被索引数组的形状一致</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ind = np.array([[<span class="number">3</span>, <span class="number">7</span>],</span><br><span class="line">                [<span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line">x[ind]</span><br></pre></td></tr></table></figure>




<pre><code>array([[71, 86],
       [60, 20]])</code></pre><ul>
<li>多维数组情况</li>
</ul>
<p>标准的索引方式一样，第一个索引指的是行，第二个索引指的是列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">row = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">col = np.array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">X[row, col]</span><br></pre></td></tr></table></figure>




<pre><code>array([ 2,  5, 11])</code></pre><p>索引遵从广播的规则，当我们将一个列向量和一个行向量组合在一个索引中时，会得到一个二维的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[row[:, np.newaxis], col]</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 2,  1,  3],
       [ 6,  5,  7],
       [10,  9, 11]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">row[:, np.newaxis] * col</span><br></pre></td></tr></table></figure>




<pre><code>array([[0, 0, 0],
       [2, 1, 3],
       [4, 2, 6]])</code></pre><h2 id="组合索引"><a href="#组合索引" class="headerlink" title="组合索引"></a>组合索引</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])</code></pre><ul>
<li>花哨索引+普通索引</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">2</span>,[<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>




<pre><code>array([10,  8,  9])</code></pre><ul>
<li>花哨索引+切片</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">1</span>:, [<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 6,  4,  5],
       [10,  8,  9]])</code></pre><ul>
<li>花哨索引 + 掩码</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mask = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], dtype=bool)</span><br><span class="line">X[row[:, np.newaxis], mask]</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0,  2],
       [ 4,  6],
       [ 8, 10]])</code></pre><h2 id="应用：选择随机点"><a href="#应用：选择随机点" class="headerlink" title="应用：选择随机点"></a>应用：选择随机点</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mean = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">cov = [[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>]]</span><br><span class="line">X = rand.multivariate_normal(mean, cov, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn; seaborn.set()  <span class="comment"># 设置绘图风格</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>]);</span><br></pre></td></tr></table></figure>


<p><img src="/2020/08/08/Python/Numpy/output_149_0.png" alt="png"></p>
<p>我们将利用花哨的索引随机选取 20 个点——选择 20 个随机的、不重复的索引值，并利用这些索引值选取到原始数组对应的值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">indices = np.random.choice(X.shape[<span class="number">0</span>], <span class="number">20</span>, replace=<span class="literal">False</span>)</span><br><span class="line">selection = X[indices]  <span class="comment"># 花哨的索引</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], alpha=<span class="number">0.3</span>)</span><br><span class="line">plt.scatter(selection[:, <span class="number">0</span>], selection[:, <span class="number">1</span>],</span><br><span class="line">facecolor=<span class="string">'none'</span>, edgecolor=<span class="string">'b'</span>, s=<span class="number">200</span>);</span><br></pre></td></tr></table></figure>


<p><img src="/2020/08/08/Python/Numpy/output_151_0.png" alt="png"></p>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line">y = np.sort(x)<span class="comment"># 不改变x</span></span><br><span class="line">y</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 2, 3, 4, 5])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>array([2, 1, 4, 3, 5])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.sort()<span class="comment"># 改变x</span></span><br><span class="line">x</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 2, 3, 4, 5])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line">i = np.argsort(x)<span class="comment"># 得到索引值</span></span><br><span class="line">i</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 0, 3, 2, 4], dtype=int64)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[i]</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 2, 3, 4, 5])</code></pre><h2 id="高维情景"><a href="#高维情景" class="headerlink" title="高维情景"></a>高维情景</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rand = np.random.RandomState(<span class="number">42</span>)</span><br><span class="line">X = rand.randint(<span class="number">0</span>, <span class="number">10</span>, (<span class="number">4</span>, <span class="number">6</span>))</span><br><span class="line">print(X)</span><br></pre></td></tr></table></figure>

<pre><code>[[6 3 7 4 6 9]
 [2 6 7 4 3 7]
 [7 2 5 4 1 7]
 [5 1 4 0 9 5]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对X的每一列排序</span></span><br><span class="line">np.sort(X, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([[2, 1, 4, 0, 1, 5],
       [5, 2, 5, 4, 3, 7],
       [6, 3, 7, 4, 6, 7],
       [7, 6, 7, 4, 9, 9]])</code></pre><p>这种处理方式是将行或列当作独立的数组，任何行或列的值之间的关系将会丢失！</p>
<h2 id="部分排序"><a href="#部分排序" class="headerlink" title="部分排序"></a>部分排序</h2><figure class="highlight plain"><figcaption><span>函数提供了该功能。```np.partition``` 函数的输入是数组和数字 K，输出结果是一个新数组，最左边是第 K 小的值，往右是任意顺序的其他值</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;python</span><br><span class="line">x &#x3D; np.array([7, 2, 3, 1, 6, 5, 4])</span><br><span class="line">np.partition(x, 3)</span><br></pre></td></tr></table></figure>




<pre><code>array([2, 1, 3, 4, 6, 5, 7])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.partition(X, <span class="number">2</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>




<pre><code>array([[3, 4, 6, 7, 6, 9],
       [2, 3, 4, 7, 6, 7],
       [1, 2, 4, 5, 7, 7],
       [0, 1, 4, 5, 9, 5]])</code></pre><p>输出结果是一个数组，该数组每一行的前两个元素是该行最小的两个值，每行的其他值分布在剩下的位置。</p>
<p>最后，正如 np.argsort 函数计算的是排序的索引值，也有一个 np.argpartition 函数计算的是分隔的索引值</p>
<h1 id="结构化数据：NumPy的结构化数组"><a href="#结构化数据：NumPy的结构化数组" class="headerlink" title="结构化数据：NumPy的结构化数组"></a>结构化数据：NumPy的结构化数组</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用复合数据结构的结构化数组</span></span><br><span class="line">data = np.zeros(<span class="number">4</span>, dtype=&#123;<span class="string">'names'</span>:(<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'weight'</span>),</span><br><span class="line">                 <span class="string">'formats'</span>:(<span class="string">'U10'</span>, <span class="string">'i4'</span>, <span class="string">'f8'</span>)&#125;)</span><br><span class="line">print(data.dtype)</span><br></pre></td></tr></table></figure>

<pre><code>[(&apos;name&apos;, &apos;&lt;U10&apos;), (&apos;age&apos;, &apos;&lt;i4&apos;), (&apos;weight&apos;, &apos;&lt;f8&apos;)]</code></pre><p>这里 U10 表示“长度不超过 10 的 Unicode 字符串”，i4 表示“4 字节（即 32 比特）整型”，f8 表示“8 字节（即 64 比特）浮点型”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">name = [<span class="string">'Alice'</span>, <span class="string">'Bob'</span>, <span class="string">'Cathy'</span>, <span class="string">'Doug'</span>]</span><br><span class="line">age = [<span class="number">25</span>, <span class="number">45</span>, <span class="number">37</span>, <span class="number">19</span>]</span><br><span class="line">weight = [<span class="number">55.0</span>, <span class="number">85.5</span>, <span class="number">68.0</span>, <span class="number">61.5</span>]</span><br><span class="line">data[<span class="string">'name'</span>] = name</span><br><span class="line">data[<span class="string">'age'</span>] = age</span><br><span class="line">data[<span class="string">'weight'</span>] = weight</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure>

<pre><code>[(&apos;Alice&apos;, 25, 55. ) (&apos;Bob&apos;, 45, 85.5) (&apos;Cathy&apos;, 37, 68. )
 (&apos;Doug&apos;, 19, 61.5)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[data[<span class="string">'age'</span>] &lt; <span class="number">30</span>][<span class="string">'name'</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([&apos;Alice&apos;, &apos;Doug&apos;], dtype=&apos;&lt;U10&apos;)</code></pre><h2 id="生成结构化数组"><a href="#生成结构化数组" class="headerlink" title="生成结构化数组"></a>生成结构化数组</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">np.dtype(&#123;<span class="string">'names'</span>:(<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'weight'</span>),</span><br><span class="line">                  <span class="string">'formats'</span>:(<span class="string">'U10'</span>, <span class="string">'i4'</span>, <span class="string">'f8'</span>)&#125;)</span><br><span class="line"></span><br><span class="line">np.dtype(&#123;<span class="string">'names'</span>:(<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'weight'</span>),</span><br><span class="line">                  <span class="string">'formats'</span>:((np.str_, <span class="number">10</span>), int, np.float32)&#125;)</span><br><span class="line"></span><br><span class="line">np.dtype([(<span class="string">'name'</span>, <span class="string">'S10'</span>), (<span class="string">'age'</span>, <span class="string">'i4'</span>), (<span class="string">'weight'</span>, <span class="string">'f8'</span>)])</span><br><span class="line"></span><br><span class="line">np.dtype(<span class="string">'S10,i4,f8'</span>)</span><br></pre></td></tr></table></figure>




<pre><code>dtype([(&apos;f0&apos;, &apos;S10&apos;), (&apos;f1&apos;, &apos;&lt;i4&apos;), (&apos;f2&apos;, &apos;&lt;f8&apos;)])</code></pre><p>第一个（可选）字符是 &lt; 或者 &gt;，分别表示“低字节序”（little endian）和“高字节序”（bid endian），表示字节（bytes）类型的数据在内存中存放顺序的习惯用法。后一个字符指定的是数据的类型：字符、字节、整型、浮点型，等等。最后一个字符表示该对象的字节大小。</p>
<table>
<thead>
<tr>
<th>NumPy数据类型符号</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>‘b’</td>
<td>字节型</td>
<td>np.dtype(‘b’)</td>
</tr>
<tr>
<td>‘i’</td>
<td>有符号整型</td>
<td>np.dtype(‘i4’) == np.int32</td>
</tr>
<tr>
<td>‘u’</td>
<td>无符号整型</td>
<td>np.dtype(‘u1’) == np.uint8</td>
</tr>
<tr>
<td>‘f’</td>
<td>浮点型</td>
<td>np.dtype(‘f8’) == np.int64</td>
</tr>
<tr>
<td>‘c’</td>
<td>复数浮点型</td>
<td>np.dtype(‘c16’) == np.complex128</td>
</tr>
<tr>
<td>‘S’、’a’</td>
<td>字符串</td>
<td>np.dtype(‘S5’)</td>
</tr>
<tr>
<td>‘U’</td>
<td>Unicode 编码字符串</td>
<td>np.dtype(‘U’) == np.str_</td>
</tr>
<tr>
<td>‘V’</td>
<td>原生数据，raw data（空，void）</td>
<td>np.dtype(‘V’) == np.void</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">机器学习/单变量线性回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-06 19:36:49 / Modified: 21:36:01" itemprop="dateCreated datePublished" datetime="2020-08-06T19:36:49+08:00">2020-08-06</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h1><p>m： 训练样本的数目</p>
<p>$(x,y)$: 训练集中的实例</p>
<p>$(x^{(i)}, y^{(i)})$: 第$i$个观察实例</p>
<p>h:代表学习算法的解决方案或函数也称为假设函数</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>我们希望下列函数值最小</p>
<p>平方误差代价函数：<br>$$J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}$$</p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>repeat until  convergence {<br>$$ \theta_{j}:=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J\left(\theta_{0}, \theta_{1}\right) \quad(\text { for } j=0 \text { and } j=1)$$</p>
<p>}</p>
<ul>
<li>Correct: Simultaneous update</li>
</ul>
<p>$temp  0:=\theta_{0}-\alpha \frac{\partial}{\partial \theta_{0}} J\left(\theta_{0}, \theta_{1}\right)$</p>
<p>$temp  1:=\theta_{1}-\alpha \frac{\partial}{\partial \theta_{1}} J\left(\theta_{0}, \theta_{1}\right)$</p>
<p>$\theta_{0}:=\operatorname{temp} 0$</p>
<p>$\theta_{1}:=  temp1$</p>
<p>$\alpha:学习率（一步迈的距离）$</p>
<p>当点接近局部最优值时，导数项会变小，因此每次更新的步长也会相应减小</p>
<h1 id="梯度下降的线性回归"><a href="#梯度下降的线性回归" class="headerlink" title="梯度下降的线性回归"></a>梯度下降的线性回归</h1><p>$$\frac{\partial}{\partial \theta_{j}} J\left(\theta_{0}, \theta_{1}\right)=\frac{\partial}{\partial \theta_{j}} \frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)$$<br>j=0  时：</p>
<p>$$ \frac{\partial}{\partial \theta_{0}} J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) $$<br>j=1  时：</p>
<p>$$ \frac{\partial}{\partial \theta_{1}} J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x^{(i)}\right) $$</p>
<p>于是上述算法可写成</p>
<p>Repeat {</p>
<p>$$\theta_{0}:=\theta_{0}-a \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) $$</p>
<p>$$\theta_{1}:=\theta_{1}-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x^{(i)}\right) $$</p>
<p>}</p>
<ul>
<li>注： $\theta_0,\ \theta_1要同时更新，否则会相互影响$</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">luyilin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">52</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        </script>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">luyilin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
