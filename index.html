<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"luyilin.top","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="引而不发，跃如也">
<meta property="og:url" content="http://luyilin.top/index.html">
<meta property="og:site_name" content="引而不发，跃如也">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="luyilin">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://luyilin.top/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>引而不发，跃如也</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">引而不发，跃如也</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">机器学习/异常检测与推荐系统</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-26 20:00:46 / Modified: 20:28:00" itemprop="dateCreated datePublished" datetime="2020-08-26T20:00:46+08:00">2020-08-26</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h1><h2 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h2><p>$$<br>P(x,\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)<br>$$</p>
<p>我们认为变量$x$符合高斯分布</p>
<p>其中</p>
<p>$$<br>\quad \mu=\frac{1}{m} \sum_{i=1}^{m} x^{(i)}$$</p>
<p>$$<br>\sigma^{2}=\frac{1}{m} \sum_{i=1}^{m}\left(x^{(i)}-\mu\right)^{2}</p>
<p>$$</p>
<p><img src="/2020/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/1.JPG" alt="1"></p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul>
<li>假设各个特征相互独立</li>
</ul>
<p>对于给定的数据集  $x^{(1)}, x^{(2)}, \ldots, x^{(m)}$,  我们要针对每一个特征计算  $\mu$  和  $\sigma^{2}$  的估计值。<br>$$\mu_{j}=\frac{1}{m} \sum_{i=1}^{m} x_{j}^{(i)}$$<br>$$\sigma_{j}^{2}=\frac{1}{m} \sum_{i=1}^{m}\left(x_{j}^{(i)}-\mu_{j}\right)^{2}$$ </p>
<p>一旦我们获得了平均值和方差的估计值，给定新的一个训练实例，根据 模型计算$p(x)$:<br>$$p(x)=\prod_{j=1}^{n} p\left(x_{j} ; \mu_{j}, \sigma_{j}^{2}\right)=\prod_{j=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma_{j}} \exp \left(-\frac{\left(x_{j}-\mu_{j}\right)^{2}}{2 \sigma_{j}^{2}}\right)$$<br>当$p(x)&lt;\varepsilon$ 时，为异常。 </p>
<h2 id="如何评估"><a href="#如何评估" class="headerlink" title="如何评估"></a>如何评估</h2><p>我们从带标记（异常或正常）的数据着手，从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。</p>
<p>例如：我们有10000台正常引擎的数据，有20台异常引擎的数据。 我们这样分配数据：</p>
<p>6000台正常引擎的数据作为训练集</p>
<p>2000台正常引擎和10台异常引擎的数据作为交叉检验集</p>
<p>2000台正常引擎和10台异常引擎的数据作为测试集</p>
<p>具体的评价方法如下：</p>
<ol>
<li>根据测试集数据，我们估计特征的平均值和方差并构建$P(x)$函数</li>
<li>对交叉检验集，我们尝试使用不同的$\varepsilon$值作为阀值，并预测数据是否异常，根据F1值或者查准率与查全率的比例来选择$\varepsilon$ </li>
<li>选出$\varepsilon$后，针对测试集进行预测，计算异常检验系统的F1值，或者查准率与查全率之比</li>
</ol>
<h2 id="异常检测与监督学习"><a href="#异常检测与监督学习" class="headerlink" title="异常检测与监督学习"></a>异常检测与监督学习</h2><table>
<thead>
<tr>
<th>异常检测</th>
<th>监督学习</th>
</tr>
</thead>
<tbody><tr>
<td>非常少量的正向类（异常数据 ）, 大量的负向类（正常数据）</td>
<td>同时有大量的正向类和负向类</td>
</tr>
<tr>
<td>许多不同种类的异常</td>
<td>有足够多的正向类实例，足够用于训练算法，未来遇到的正向类实例可能与训练集中的非常近似。</td>
</tr>
<tr>
<td>未来遇到的异常可能与已掌握的异常、非常的不同。</td>
<td></td>
</tr>
</tbody></table>
<h2 id="选择特征"><a href="#选择特征" class="headerlink" title="选择特征"></a>选择特征</h2><h3 id="通过变换使特征满足高斯分布"><a href="#通过变换使特征满足高斯分布" class="headerlink" title="通过变换使特征满足高斯分布"></a>通过变换使特征满足高斯分布</h3><p><img src="/2020/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2.JPG" alt="2"><br>$$x = log(x + c)$$<br>$$x = x^c$$</p>
<h3 id="通过误差分析找到新特征"><a href="#通过误差分析找到新特征" class="headerlink" title="通过误差分析找到新特征"></a>通过误差分析找到新特征</h3><p>从被误判成正常的异常中找到与其他对象所不同的特征</p>
<p>如CPU负载与网络通信量的比例</p>
<h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" class="post-title-link" itemprop="url">机器学习/无监督学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-25 14:20:18 / Modified: 15:35:10" itemprop="dateCreated datePublished" datetime="2020-08-25T14:20:18+08:00">2020-08-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><h2 id="K均值"><a href="#K均值" class="headerlink" title="K均值"></a>K均值</h2><p>迭代算法</p>
<ol>
<li><p>选取K个随机点作为聚类中心，遍历数据集所有点，按照距离K个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</p>
</li>
<li><p>计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。</p>
</li>
<li><p>重复直到中心点不再变化</p>
</li>
</ol>
<h2 id="记号表示"><a href="#记号表示" class="headerlink" title="记号表示"></a>记号表示</h2><p>$c^{(i)}:x^{(i)}$所属的类</p>
<p>$\mu_k:$第k类中心点的位置</p>
<p>$\mu_{c^{(i)}}:x^{(i)}$点所属类的中心点的位置</p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>$$<br>J\left(c^{(1)}, \ldots, c^{(m)}, \mu_{1}, \ldots, \mu_{K}\right)=\frac{1}{m} \sum_{i=1}^{m}\left|X^{(i)}-\mu_{c^{(i)}}\right|^{2}<br>$$</p>
<p>回顾刚才给出的: K-均值迭代算法，我们知道，第一个循环是用于减小$c^{(i)}$引起的代价，而第二个循环则是用于减小$\mu_i$引起的代价。迭代的过程一定会是每一次迭代都在减小代价函数，不然便是出现了错误。</p>
<h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><ol>
<li>$K&lt;m$</li>
<li>随机选择K个训练实例，然后令K个聚类中心分别与这K个训练实例相等</li>
</ol>
<p>多次运行K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行K-均值的结果，选择代价函数最小的结果。这种方法在K较小的时候（2–10）还是可行的，但是如果K较大，这么做也可能不会有明显地改善。</p>
<h2 id="选择聚类数"><a href="#选择聚类数" class="headerlink" title="选择聚类数"></a>选择聚类数</h2><ol>
<li>肘部法则<br><img src="/2020/08/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1.JPG" alt="1"></li>
<li>按实际需求选择</li>
</ol>
<h1 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h1><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ul>
<li>数据压缩<ul>
<li>加速监督算法</li>
</ul>
</li>
<li>可视化 </li>
</ul>
<h2 id="主成分分析（PCA）"><a href="#主成分分析（PCA）" class="headerlink" title="主成分分析（PCA）"></a>主成分分析（PCA）</h2><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>找到一个方向向量（Vector direction），当我们把所有的数据都投射到该向量上时，我们希望投射平均均方误差能尽可能地小。方向向量是一个经过原点的向量，而投射误差是从特征向量向该方向向量作垂线的长度。</p>
<p>主成分分析与线性回归是两种不同的算法。主成分分析最小化的是投射误差（Projected Error），而线性回归尝试的是最小化预测误差。线性回归的目的是预测结果，而主成分分析不作任何预测。</p>
<h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>将n维减少的k维</p>
<ol>
<li>均值归一化：如果特征是在不同的数量级上，我们还需要将其除以标准差$\sigma^2$。</li>
<li>第二步是计算协方差矩阵（covariance matrix）<br>$$\Sigma=\frac{1}{m} \sum_{i=1}^{n}\left(x^{(i)}\right)\left(x^{(i)}\right)^{T}$$</li>
<li>奇异值分解<br><code>[U,S,V] = svd(sigma)</code><br>对于一个  $n \times n$  维度的矩阵, 上式中的U是一个具有与数据之间最小投射误差的方向向量构成的矩阵。如果我们希望将数据从$n$维降至  $k$  维，我们只需要从U中选取前k个向量，获得一个$n\times k$维度的矩阵，我们用  $U_{\text {reduce}}$  表示，然后通过如下计算获得要求的新特征向量  $z^{(i)}$  :<br>$$z^{(i)}=U_{r e d u c e}^{T} * x^{(i)}$$<br>其中  $x$  是  $n \times 1$  维的，因此结果为  $k \times 1$  维度。<h2 id="主成分数量"><a href="#主成分数量" class="headerlink" title="主成分数量"></a>主成分数量</h2>我们获得三个参数：<code>[U, S, V] = svd(sigma)</code>。<br>其中的S是一个$n\times n$的矩阵，只有对角线上有值，而其它单元都是0</li>
</ol>
<p>我们可以使用这个矩阵来计算平均均方误差与训练集方差的比例 :<br>$$<br>\frac{\frac{1}{m} \sum_{i=1}^{m}\left|x^{(i)}-x_{a p p r o x}^{(i)}\right|^{2}}{\frac{1}{m} \sum_{i=1}^{m}\left|x^{(i)}\right|^{2}}=1-\frac{\Sigma_{i=1}^{k} S_{i i}}{\Sigma_{i=1}^{m} S_{i i}} \leq 1 %<br>$$<br>也就是：<br>$$\quad \frac{\Sigma_{i=1}^{k} s_{i i}}{\Sigma_{i=1}^{n} s_{i i}} \geq 0.99$$<br>在压缩过数据后，我们可以采用如下方法来近似地获得原有的特征:<br> $$x_{a p p r o x}^{(i)}=U_{r e d u c e} z^{(i)}$$ </p>
<h2 id="压缩的还原"><a href="#压缩的还原" class="headerlink" title="压缩的还原"></a>压缩的还原</h2><p>$$z=U_{\text {reduce}}^{T} x$$<br>相反的方程为：<br>$$x_{a p p o x}=U_{r e d u c e} \cdot z_{1}$$<br>$$x_{a p p o x} \approx x $$</p>
<h2 id="应用建议"><a href="#应用建议" class="headerlink" title="应用建议"></a>应用建议</h2><ol>
<li>PCA不能防止过拟合</li>
<li>在学习时可以先不用PCA降维操作一遍看看是否能得到好的结构，如果不能再考虑PCA</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA(Support%20Vector%20Machines)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA(Support%20Vector%20Machines)/" class="post-title-link" itemprop="url">机器学习/支持向量机(Support Vector Machines)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-24 09:06:01 / Modified: 21:18:49" itemprop="dateCreated datePublished" datetime="2020-08-24T09:06:01+08:00">2020-08-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。</p>
<h1 id="构建支持向量机"><a href="#构建支持向量机" class="headerlink" title="构建支持向量机"></a>构建支持向量机</h1><p><img src="/2020/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA(Support%20Vector%20Machines)/1.JPG" alt="1"></p>
<ul>
<li>修改了逻辑回归中的代价函数</li>
</ul>
<p>$$J(\theta)=\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} (-\log \left(h_{\theta}\left(x^{(i)}\right)\right))+\left(1-y^{(i)}\right) (-\log \left(1-h_{\theta}\left(x^{(i)}\right)\right))\right]+ \frac{\lambda}{2m}\sum_{j = 1}^n\theta_j^2$$</p>
<p>修改代价函数<br>$$J(\theta)=\sum_{i=1}^{m}\left[y^{(i)} cost_1(\theta^Tx^{(i)})+\left(1-y^{(i)}\right) cost_0(\theta^Tx^{(i)})\right]+ \frac{\lambda}{2}\sum_{j = 1}^n\theta_j^2$$</p>
<p>$$min(A + \lambda B)\rightarrow min(CA + B), C = \frac{1}{\lambda}$$</p>
<p>$$J(\theta)=C\sum_{i=1}^{m}\left[y^{(i)} cost_1(\theta^Tx^{(i)})+\left(1-y^{(i)}\right) cost_0(\theta^Tx^{(i)})\right]+ \frac{1}{2}\sum_{j = 1}^n\theta_j^2$$</p>
<h1 id="大边界"><a href="#大边界" class="headerlink" title="大边界"></a>大边界</h1><p>希望$\theta^Tx&gt;=1$</p>
<p>大间距分类器，C越大对异常点越敏感</p>
<p>$C = \frac{1}{\lambda}$，因此：</p>
<p>$C$较大时，相当于$\lambda$较小，可能会导致过拟合，高方差。</p>
<p>$C$较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差。</p>
<h1 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h1><p><img src="/2020/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA(Support%20Vector%20Machines)/2.JPG" alt="2"></p>
<p>高斯核函数</p>
<p>$$f_i = exp(-\frac{||x - l^{(i)}||^2}{2\sigma^2})$$</p>
<p>$$<br>h_{\theta}(x)=\theta_{0}+\theta_{1} f_{1}+\theta_{2} f_{2}+\theta_{1} f_{3}&gt;0, \text { 则预测 } y=1 .<br>$$</p>
<p>$\sigma$较大时，可能会导致低方差, 高偏差;</p>
<p>$\sigma$较小时，可能会导致低偏差, 高方差。</p>
<ul>
<li>如何选择特征点？将训练集作为特征点带入即可</li>
</ul>
<h1 id="算法选择"><a href="#算法选择" class="headerlink" title="算法选择"></a>算法选择</h1><p>$n &gt; m$ 逻辑回归</p>
<p>$n &lt; m$   </p>
<ul>
<li>m较小，例如$n$在1-1000 之间，而$m$在10-10000之间，SVM高斯核函数</li>
<li>m较大，例如$n$在1-1000之间，而$m$大于50000,SVM线性核函数/逻辑回归</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">数据挖掘/04 分类基础</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-23 09:07:31 / Modified: 14:18:55" itemprop="dateCreated datePublished" datetime="2020-08-23T09:07:31+08:00">2020-08-23</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h1><p><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/1.JPG" alt="1"><br>$$<br>\text{准确率} = \frac{\text{正确预测数}}{预测总数} = \frac{f_{11}+ f_{00}}{f_{11}+f_{00}+f_{10}+f_{01}}<br>$$</p>
<p>$$<br>\text{错误率} = \frac{\text{错误预测数}}{预测总数} = \frac{f_{10}+ f_{01}}{f_{11}+f_{00}+f_{10}+f_{01}}<br>$$</p>
<h1 id="决策树归纳"><a href="#决策树归纳" class="headerlink" title="决策树归纳"></a>决策树归纳</h1><h2 id="建立决策树"><a href="#建立决策树" class="headerlink" title="建立决策树"></a>建立决策树</h2><ol>
<li>Hunt算法<br>以递归方式建立决策树</li>
<li>决策树算法的设计问题<ol>
<li>如何分裂训练记录？</li>
<li>如何停止分裂过程？</li>
</ol>
</li>
</ol>
<h2 id="表示属性测试条件的方法"><a href="#表示属性测试条件的方法" class="headerlink" title="表示属性测试条件的方法"></a>表示属性测试条件的方法</h2><ul>
<li><p>二元属性<br>  产生两个可能的输出</p>
</li>
<li><p>标称属性</p>
<ul>
<li>多路划分</li>
<li>二元划分</li>
</ul>
<p><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/2.JPG" alt="2"></p>
</li>
<li><p>序数属性（暗含序关系）</p>
<p><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/3.JPG" alt="3"></p>
<p>c方法非法</p>
</li>
<li><p>连续属性<br><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/4.JPG" alt="4"></p>
</li>
</ul>
<h2 id="选择最佳划分的度量"><a href="#选择最佳划分的度量" class="headerlink" title="选择最佳划分的度量"></a>选择最佳划分的度量</h2><p>设$P(i|t)$表示给定结点$t$中属于类$i$的纪录所占的比例</p>
<p>选则最佳划分的度量通常是根据划分后子女结点不纯性的程度。不纯的程度越低，类分布就越倾斜。例如，类分布为(0, 1)的结点量有零不纯性，而均衡分布 (0.5,0.5) 的结点具有最高的不纯性。</p>
<p>$$<br>\text { Entropy }(t) =-\sum_{i=0}^{c-1} p(i \mid t) \log _{2} p(i \mid t)<br>$$</p>
<p>$$<br>\operatorname{Gini}(t) =1-\sum_{i=0}^{c-1}[p(i \mid t)]^{2} <br>$$<br>$$<br>\text { Classification } \operatorname{error}(t) =1-\max _{i}[p(i \mid t)]<br>$$</p>
<p>$$<br>其中 c 是类的个数，并且在计算熵时，Olog_0 = 0<br>$$<br><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/5.JPG" alt="5"><br><img src="/2020/08/23/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/04%20%E5%88%86%E7%B1%BB%E5%9F%BA%E7%A1%80/6.JPG" alt="6"></p>
<p>为了确定将试条件的效果，我们需要比较父结点 (划分前) 的不纯程度和子女结点 (划分后) 的不纯程度，它们的差越大，测试条件的效果就越好。增益是一种可以用来确定划分效果的</p>
<p>$$<br>\Delta=I(\text { parent })-\sum_{j=1}^{k} \frac{N\left(v_{j}\right)}{N} I\left(v_{j}\right)<br>$$</p>
<p>其中，I是给定结点的不纯性度量，$N$是父结点上的记录总数，$k$ 是属性值的个数，$N(v_j)$是与子女结点  $v_{j}$  相关联的记录个数。决策树归纳算法通常选则最大化增益$\Delta$的测试条件，因为对所有的测试条件来说，$I(parent)$是一个不变的值，所以最大化增益等价于最小化子女结点的不纯性度量的加权平均值。最后，当选择熵（entropy）作为公式的不纯性度量时，熵的差就是所谓<strong>信息增益(information gain)</strong> $\Delta_{\text {info }}$ </p>
<h2 id="决策树归纳算法"><a href="#决策树归纳算法" class="headerlink" title="决策树归纳算法"></a>决策树归纳算法</h2><p>该算法的输入是训练记录集 E 和属性集F</p>
<ol>
<li>函数 <code>createdNode()</code> 为决策树建立新结点。决策树的结点或者是一个测试条件，记作 <code>node.test_cond</code>，或者是一个类标号，记作 <code>node.label</code></li>
<li>函数 <code>find_best_split()</code>确定应当选择哪个属性作为划分训练记录的测试条件。可用熵、Gini 指标和 $\chi^2$ 统计量进行度量。</li>
<li>函数 <code>Classify()</code> 为叶结点确定类标号。对于每个叶结点  t,  令  $p(i \mid t)$  表示该结点上属于类 $i$ 的训练记录所占的比例，在大多数情况下，都将叶结点指派到具有多数记录的类:</li>
</ol>
<p>$$\text {leaf.label}=\underset{i}{\operatorname{argmax}} p(i \mid t)$$</p>
<p>其中，操作 argmax 返回最大化  $p(i \mid t)$  的参数值  $i。p(i \mid t)$  除了提供确定叶结点类标号所需要的信息之 外，还可以用来估计分配到叶结点  $t$  的记录属于类  $i$  的概率。</p>
<ol start="4">
<li>函数 <code>stopping_cond()</code> 通过检查是否所有的记录都属于同一个类, 或者都具有相同的属性值，决定是否终止决策树的增长。终止递归函数的另一种方法是，检查记录数是否小与某个最小阈值。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">TreeGrowth(E,F)</span><br><span class="line">    <span class="keyword">if</span> stopping_cond(E,F) = <span class="literal">True</span>:</span><br><span class="line">        leaf = creatNode()</span><br><span class="line">        leaf.label = Classify(E)</span><br><span class="line">        <span class="keyword">return</span> leaf</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        root = creatNode()</span><br><span class="line">        root.test_cond = find_best_split(E,F)</span><br><span class="line">        V = &#123;v| v 是 root.test_cond 的一个可能输出&#125;</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> V:</span><br><span class="line">            Ev = &#123;e|root.test_cond(e) = v 且e <span class="keyword">in</span> E&#125;</span><br><span class="line">            child = TreeGrowth(Ev,F)</span><br><span class="line">            将child加入树中，并添加边(root-&gt;child)标记为v</span><br><span class="line">    <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="决策树特点"><a href="#决策树特点" class="headerlink" title="决策树特点"></a>决策树特点</h2><ol>
<li>不要求任何先验经验，不假定属性服从概率分布</li>
<li>NP完全问题</li>
<li>决策树一旦建立，分类速度很快，最坏$O(w),w$为深度</li>
<li>有较好的鲁棒性</li>
<li>冗余属性不会对决策树准确性造成不良影响</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/22/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/03%20%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/22/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/03%20%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">数据挖掘/03 探索数据</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-22 09:09:04 / Modified: 11:09:38" itemprop="dateCreated datePublished" datetime="2020-08-22T09:09:04+08:00">2020-08-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="汇总统计"><a href="#汇总统计" class="headerlink" title="汇总统计"></a>汇总统计</h1><ul>
<li><p>量化的</p>
</li>
<li><p>用单个数据或数的小集合捕获可能很大的值集的各种特征</p>
</li>
<li><p>例子：家庭平均收入，四年完成本科学业的比例</p>
<h2 id="频率和众数"><a href="#频率和众数" class="headerlink" title="频率和众数"></a>频率和众数</h2><p>分类属性比较合适，连续数据往往不适合</p>
<h2 id="百分位数"><a href="#百分位数" class="headerlink" title="百分位数"></a>百分位数</h2><p>对于有序数集，考虑百分位数</p>
<h2 id="均值与中位数"><a href="#均值与中位数" class="headerlink" title="均值与中位数"></a>均值与中位数</h2><p>对于连续数据的描述</p>
</li>
<li><p>截断均值：丢弃部分最高最低数据后的均值</p>
<h2 id="散布度量：极差与方差"><a href="#散布度量：极差与方差" class="headerlink" title="散布度量：极差与方差"></a>散布度量：极差与方差</h2><p>连续数据的另一个常用汇总统计</p>
</li>
<li><p>极差：最大减最小</p>
</li>
<li><p>方差</p>
</li>
<li><p>标准差：方差的平方根</p>
</li>
<li><p>绝对平均偏差（ADD）：<br>$$ADD(x) = \frac{1}{m}\sum_{i = 1}^m|x_i - \bar{x}|$$</p>
</li>
<li><p>中位数绝对偏差：<br>$$MAD(x) = median({|x_1 - \bar{x}|,…,|x_m - \bar{x}|})$$</p>
</li>
<li><p>四分卫数极差<br>$$IRQ = x_{75%} - x_{25%}$$</p>
</li>
</ul>
<h2 id="多元汇总统计"><a href="#多元汇总统计" class="headerlink" title="多元汇总统计"></a>多元汇总统计</h2><p>散布：协方差矩阵</p>
<p>其中，$S$ 的第$i j$个元素  $s_{i j}$  是数据的第  $i$  个和第  $j$  个属性的协方差。这样，如果  $x_{i}$  和  $x_{j}$  分别是第  $i$  个和第 $j$ 个属性，则<br>$$<br>s_{i j}=\operatorname{covariance}\left(x_{i}, x_{j}\right)<br>$$<br>而 $covariance  \left(x_{i}, x_{j}\right)$  由<br>$$<br>\operatorname{covariance}\left(x_{i}, x_{j}\right)=\frac{1}{m-1} \sum_{k=1}^{m}\left(x_{k i}-\bar{x}<em>{i}\right)\left(x</em>{k j}-\bar{x}<em>{j}\right)<br>$$<br>给出,其中  $x</em>{k i}$  和  $x_{k j}$  分别是第  $k$  个对象的第  $i$  和第  $j$  个属性的值. 注意, $covariance  \left(x_{i}, x_{i}\right)=  variance  \left(x_{i}\right)$  </p>
<p>这样，协方差矩阵的对角线上是属性的方差。</p>
<p>两个属性的协方差是两个属性一起变化并依赖于变量大小的度量。协方差的值接近于 0 表明 两个变最不具有（线性）关系，但是不能仅观察协方差的值来确定两个变量之间的关联程度。 因为两个属性的相关性直接指出两个属性（线性）相关的程度，对于数据探索，相关性比协方差更可取。相关矩阵（correlation matrix）$R$ 的第  $i j$个元素是数据 的第 $i$ 个和第 $j$ 个属性之间的相关性。如果  $x_{i}$  和  $x_{j}$ 分别是第  $i$  个和第  $j$  个属性，则<br>$$<br>r_{i j}=\text { correlation }\left(x_{i}, x_{j}\right)=\frac{\text { covariance }\left(x_{i}, x_{j}\right)}{s_{i} s_{j}}<br>$$</p>
<p>其中，$s_i$和  $s_{j}$  分别是  $x_{i}$  和  $x_{j}$  的方差。R 的对角线上的元素是 $correlation  \left(x_{l}, x_{i}\right)=1$,  而其他元素在-1 和 1 之间。考虑包含每对对像而不是每对属性之间相关性的相关矩阵也是有用的。</p>
<h1 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h1><p>茎叶图，直方图，二维直方图，盒状图，饼图，散布图，等高线图，曲面图，矢量场图，低维切片</p>
<h1 id="联机分析处理-OLAP-和多维数据分析"><a href="#联机分析处理-OLAP-和多维数据分析" class="headerlink" title="联机分析处理(OLAP)和多维数据分析"></a>联机分析处理(OLAP)和多维数据分析</h1>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/" class="post-title-link" itemprop="url">机器学习/应用机器学习的建议</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-21 20:19:46" itemprop="dateCreated datePublished" datetime="2020-08-21T20:19:46+08:00">2020-08-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-23 21:19:41" itemprop="dateModified" datetime="2020-08-23T21:19:41+08:00">2020-08-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="评估算法性能"><a href="#评估算法性能" class="headerlink" title="评估算法性能"></a>评估算法性能</h1><p>如何判断假设函数是否过拟合？ 对假设函数画图</p>
<p>维数过多？按7：3的比例划分成训练集和测试集</p>
<ul>
<li>对于线性回归模型，计算$J(\theta)$,计算测试集的误差</li>
<li>对于逻辑回归模型，除了计算代价函数，还可以计算误分类比率</li>
</ul>
<p>$$err\left(h_{\theta}(x), y\right)= 1 \text { if } h(x) \geq 0.5 \text { and } y=0 \text { , or if } h(x)&lt;0.5 \text { and } y=1$$<br>$$err\left(h_{\theta}(x), y\right)=  0 \text { Otherwise }$$</p>
<p>然后对计算结果求平均</p>
<p>$$<br>Testerror = \frac{\sum err}{m}<br>$$</p>
<h1 id="模型选择和交叉验证集"><a href="#模型选择和交叉验证集" class="headerlink" title="模型选择和交叉验证集"></a>模型选择和交叉验证集</h1><p>假设我们要在10个不同次数的二项式模型之间进行选择，越高次数的多项式模型越能够适应我们的训练数据集，但是适应训练数据集并不代表着能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们需要使用交叉验证集来帮助选择模型。</p>
<p>使用60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用20%的数据作为测试集。</p>
<ul>
<li>模型选择的方法为：</li>
</ul>
<ol>
<li><p>使用训练集训练出10个模型</p>
</li>
<li><p>用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</p>
</li>
<li><p>选取代价函数值最小的模型</p>
</li>
<li><p>用步骤3中选出的模型对测试集计算得出推广误差（代价函数的值）</p>
</li>
</ol>
<p>Training error:<br>$$J_{t r a i n}(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2} $$</p>
<p>Cross Validation error:<br>$$ J_{c v}(\theta)=\frac{1}{2 m_{c v}} \sum_{i=1}^{m}\left(h_{\theta}\left(x_{c v}^{(i)}\right)-y_{c v}^{(i)}\right)^{2} $$<br>Test error:<br>$$ J_{\text {test}}(\theta)=\frac{1}{2 m_{\text {test}}} \sum_{i=1}^{m_{\text {test}}}\left(h_{\theta}\left(x_{c v}^{(i)}\right)-y_{c v}^{(i)}\right)^{2} $$</p>
<h1 id="诊断偏差和方差"><a href="#诊断偏差和方差" class="headerlink" title="诊断偏差和方差"></a>诊断偏差和方差</h1><p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/1.JPG" alt="1"><br>横轴从欠拟合逐渐走向过拟合</p>
<p>high bias (偏差) 意味模型简单，欠拟合<br>high variance(方差) 意味模型复杂，过拟合</p>
<p>训练集误差和交叉验证集误差近似时：偏差/欠拟合 交叉验证集误差远大于训练集误差时：方差/过拟合</p>
<h1 id="正则化和偏差-方差"><a href="#正则化和偏差-方差" class="headerlink" title="正则化和偏差/方差"></a>正则化和偏差/方差</h1><p>$$<br>J(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}+\frac{\lambda}{2 m} \sum_{j=1}^{m} \theta_{j}^{2}$$</p>
<p>$$<br>J_{\text {train}}(\theta)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}$$</p>
<p>$$<br>J_{c v}(\theta)=\frac{1}{2 m_{c v}} \sum_{i=1}^{m_{c v}}\left(h_{\theta}\left(x_{c v}^{(i)}\right)-y_{c v}^{(i)}\right)^{2}<br>$$</p>
<p>选择的方法为：</p>
<p>$\lambda = 0,0.01,0.02,0.04,…10$</p>
<ol>
<li>使用训练集训练出12个不同程度正则化的模型</li>
<li>用12个模型分别对交叉验证集计算的出交叉验证误差</li>
<li>选择得出交叉验证误差最小的模型</li>
<li>运用步骤3中选出模型对测试集计算得出推广误差，我们也可以同时将训练集和交叉验证集模型的代价函数误差与λ的值绘制在一张图表上：</li>
</ol>
<p>当$\lambda$  较小时，训练集误差较小（过拟合）而交叉验证集误差较大 </p>
<p>随着$\lambda$的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</p>
<p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/2.JPG" alt="2"></p>
<h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><h2 id="最开始"><a href="#最开始" class="headerlink" title="最开始"></a>最开始</h2><p>画出$J_{\text {train}}(\theta)$,$J_{c v}(\theta)$关于训练集m个数的变化趋势</p>
<p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/3.JPG" alt="3"></p>
<h2 id="进一步讨论"><a href="#进一步讨论" class="headerlink" title="进一步讨论"></a>进一步讨论</h2><p>cv集的数量不变，考虑用欠拟合的模型，随着训练集的增大，误差增大但是会最终停留在一个较高值，cv同理先减小后停留在较高值。</p>
<p><img src="/2020/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/4.JPG" alt="4"></p>
<ul>
<li>高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。</li>
</ul>
<p>考虑过拟合的情况，随着训练集的增大，训练集误差增大，交叉验证集误差减小，但会一直减小，增大数据集对于过拟合的情况有用。</p>
<ul>
<li>高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。<h1 id="下一步做什么"><a href="#下一步做什么" class="headerlink" title="下一步做什么"></a>下一步做什么</h1></li>
</ul>
<ol>
<li>获得更多的训练样本——解决高方差</li>
<li>尝试减少特征的数量——解决高方差</li>
<li>尝试获得更多的特征——解决高偏差</li>
<li>尝试增加多项式特征——解决高偏差</li>
<li>尝试减少正则化程度λ——解决高偏差</li>
<li>尝试增加正则化程度λ——解决高方差</li>
</ol>
<h2 id="神经网络的方差和偏差"><a href="#神经网络的方差和偏差" class="headerlink" title="神经网络的方差和偏差"></a>神经网络的方差和偏差</h2><p>使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。 </p>
<p>通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。 对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">数据挖掘/数据</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-21 08:36:15 / Modified: 20:18:17" itemprop="dateCreated datePublished" datetime="2020-08-21T08:36:15+08:00">2020-08-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="属性与度量"><a href="#属性与度量" class="headerlink" title="属性与度量"></a>属性与度量</h2><h3 id="属性的不同类型"><a href="#属性的不同类型" class="headerlink" title="属性的不同类型"></a>属性的不同类型</h3><ul>
<li>数值的如下属性（操作）常常用来描述属性</li>
</ul>
<ol>
<li>相异性</li>
<li>序</li>
<li>加法</li>
<li>乘法</li>
</ol>
<p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/1.JPG" alt="1"></p>
<p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/2.JPG" alt="2"></p>
<ul>
<li><p>用值的个数描述属性： 离散的、连续的</p>
</li>
<li><p>非对称属性<br>对于非对称属性，出现非0值才使重要的</p>
</li>
</ul>
<h2 id="数据集的类型"><a href="#数据集的类型" class="headerlink" title="数据集的类型"></a>数据集的类型</h2><ol>
<li>数据集的一般特性<br>维度、稀疏性、分辨率</li>
<li>记录数据<ul>
<li>事务数据：项的集合的集族，纪录的集合</li>
<li>数据矩阵</li>
<li>稀疏数据矩阵</li>
</ul>
</li>
<li>基于图形的数据（纪录对象之间的联系、图形作为对象如化学结构）</li>
<li>有序数据</li>
<li>时序数据</li>
<li>空间数据</li>
</ol>
<h1 id="数据质量"><a href="#数据质量" class="headerlink" title="数据质量"></a>数据质量</h1><ol>
<li>数据质量问题的纠正和检测</li>
<li>数据清理</li>
</ol>
<h2 id="测量和数据收集问题"><a href="#测量和数据收集问题" class="headerlink" title="测量和数据收集问题"></a>测量和数据收集问题</h2><ol>
<li>测量误差和收集误差</li>
<li>噪声和伪像<br> 噪声是测量误差的随机部分<br> <img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/3.JPG" alt="3"><br> 伪像： 数据出现的确定性失真</li>
<li>精度、偏倚和准确率<br>精度：重复测量值之间的接近程度，通常用集合的标准差度量<br>偏倚：测量值与被测量值之间的系统的变差，用集合的均值与测出的已知值之间的差度量</li>
</ol>
<p>   准确率：被测量的测量值与实际值之间的接近度</p>
<ol start="4">
<li><p>离群点<br> 合法的对象、异常</p>
</li>
<li><p>遗漏值</p>
<ul>
<li>删除数据对象或属性</li>
<li>估计遗漏值</li>
<li>忽略遗漏值（仅是用没有遗漏值的属性进行计算）</li>
</ul>
</li>
<li><p>不一致的值（需要对数据更正）</p>
</li>
<li><p>重复数据</p>
</li>
</ol>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><blockquote>
<p>数据是高质量的，如果它适合预期的应用</p>
</blockquote>
<ul>
<li>时效性</li>
<li>相关性</li>
</ul>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="聚集"><a href="#聚集" class="headerlink" title="聚集"></a>聚集</h2><ul>
<li>将两个或多个对象合并成单个对象</li>
<li>聚集是删除属性的过程，或者压缩特定属性不同值个数的过程，如将日期从可能的365天压缩到12个月</li>
</ul>
<p>动机：</p>
<ul>
<li>节约内存、时间</li>
<li>起到范围或者标度转换的作用</li>
<li>更稳定</li>
</ul>
<h2 id="抽样"><a href="#抽样" class="headerlink" title="抽样"></a>抽样</h2><ul>
<li><p>选择数据对象子集进行分析的常用方法</p>
</li>
<li><p>动机：压缩数据量，以便使用更好但是开销更大的算法</p>
</li>
<li><p>主要原理：<br>样本数据在我们感兴趣的性质上（如平均值）域原数据集近似，则样本室友代表性的，进而使用样本和使用整个数据集的效果几乎一样</p>
</li>
</ul>
<ol>
<li>抽样方法<ul>
<li>简单随机抽样（有放回、无放回）</li>
<li>分层抽样</li>
</ul>
</li>
</ol>
<p>注： 抽样会导致一定程度上的信息损失</p>
<ol start="2">
<li>渐进抽样<br>从小样本开始，逐渐增加样本容量直至的达到足够容量的样本</li>
</ol>
<h2 id="维归约"><a href="#维归约" class="headerlink" title="维归约"></a>维归约</h2><ul>
<li>将一些旧属性合并在一起来降低数据集的维度</li>
</ul>
<p>注：通过选择旧属性的子集得到新属性，这种维归约成为特征子集选择或特征选择</p>
<ul>
<li>删除不相关的特征并降低噪声，避免维灾难</li>
<li>关键： 主成分分析（PCA）</li>
</ul>
<h2 id="特征子集选择"><a href="#特征子集选择" class="headerlink" title="特征子集选择"></a>特征子集选择</h2><ul>
<li>选择特征的一个子集</li>
</ul>
<h3 id="特征选择方法"><a href="#特征选择方法" class="headerlink" title="特征选择方法"></a>特征选择方法</h3><ol>
<li>嵌入方法</li>
</ol>
<p>决策树分类器<br>2. 过滤方法</p>
<p>在数据挖掘算法之前进行特征选择</p>
<ol start="3">
<li>包装方法<br>将可能的特征子集作为数据挖掘算法的输入，选出产生最好结果的子集</li>
</ol>
<ul>
<li>也可以进行特征加权</li>
</ul>
<p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/4.JPG" alt="4"></p>
<h2 id="特征创建"><a href="#特征创建" class="headerlink" title="特征创建"></a>特征创建</h2><ol>
<li>特征提取</li>
<li>映射数据到新的空间<br>傅里叶变换</li>
<li>特征构造：密度</li>
</ol>
<h2 id="离散化和二元化"><a href="#离散化和二元化" class="headerlink" title="离散化和二元化"></a>离散化和二元化</h2><ol>
<li>二元化<br><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/5.JPG" alt="5"></li>
<li>连续属性离散化<ul>
<li>非监督离散化：等宽、等频率（将相同数量的对象放进每个区间）、等深、K均值</li>
<li>监督化离散：</li>
</ul>
</li>
</ol>
<pre><code>定义  熵：


设$k$是不同的类标号数，$m_i$是某划分的第$i$个区间中值的个数，$m_{ij}$是区间$i$中类$j$的值的个数，第$i$个区间的熵$e_i$由如下等式给出
$$e_i = -\sum_{j = 1}^k\ p_{ij}\ log_2P_{ij}$$

其中
$$p_{ij} = m_{ij}/m_{i}$$
是第$i$个区间中类$j$的概率。该划分的总熵$e$是每个区间熵的加权平均，即

$$e = \sum_{i = 1}^n\ w_ie_i$$

其中
$$w_i = m_i/m,\ m为值的个数$$ 
![6](6.JPG)</code></pre><h2 id="变量变换"><a href="#变量变换" class="headerlink" title="变量变换"></a>变量变换</h2><ol>
<li><p>简单函数<br>$$x^k,log \ x,e^x,\sqrt{x},|x|$$</p>
</li>
<li><p>规范化或标准化</p>
</li>
</ol>
<p>统计学中的标准化：<br>$$x’ = \frac{(x - \bar{x})}{s_x}$$</p>
<p>$s_x为标准差$</p>
<p>数据挖掘中的标准化：</p>
<ol>
<li>用中位数取代均值</li>
<li>用标准绝对差取代标准差</li>
</ol>
<p>标准绝对差：<br>$$\sigma = \sum_{i = 1}^m|x_i - \mu_i|$$</p>
<p>其中，m是对象个数，$\mu$是均值或中位数</p>
<h1 id="相似性和相异性的度量"><a href="#相似性和相异性的度量" class="headerlink" title="相似性和相异性的度量"></a>相似性和相异性的度量</h1><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul>
<li><p>相似度： 两个对象之间的相似程度。取值范围：0（不相似）-1（相似）</p>
</li>
<li><p>相异度（距离）：两个对象的差异程度。取值范围： 0（相同）-1/正无穷</p>
</li>
</ul>
<h3 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h3><p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/7.JPG" alt="7"></p>
<h2 id="简单属性"><a href="#简单属性" class="headerlink" title="简单属性"></a>简单属性</h2><p><img src="/2020/08/21/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE/8.JPG" alt="8"></p>
<h2 id="数据对象之间的相异度"><a href="#数据对象之间的相异度" class="headerlink" title="数据对象之间的相异度"></a>数据对象之间的相异度</h2><p>定义r-范数</p>
<ul>
<li>r = 1 为曼哈顿距离</li>
<li>r = 2 为欧几里得距离</li>
<li>r = $+\infit$为属性之间的对大值</li>
</ul>
<p>满足非负性，对称性，三角不等式，进而引入度量</p>
<h2 id="数据对象之间的相似度"><a href="#数据对象之间的相似度" class="headerlink" title="数据对象之间的相似度"></a>数据对象之间的相似度</h2><p>对于相似度，三角不等式通常不成立</p>
<h2 id="邻近性度量的例子"><a href="#邻近性度量的例子" class="headerlink" title="邻近性度量的例子"></a>邻近性度量的例子</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/16/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%A4%A7%E5%AD%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/16/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%A4%A7%E5%AD%A6/" class="post-title-link" itemprop="url">读书笔记/大学</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-16 19:26:47" itemprop="dateCreated datePublished" datetime="2020-08-16T19:26:47+08:00">2020-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-19 08:41:52" itemprop="dateModified" datetime="2020-08-19T08:41:52+08:00">2020-08-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在多样性中追寻普遍性，在普遍性中尊重多样性</p>
<p>真理的死亡就意味着道德的死亡，而道德的死亡就以为着</p>
<p>《哲学的故事》<br>《人性七论》</p>
<h1 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h1><p>对立立场有相对的合理性</p>
<h1 id="培养责任"><a href="#培养责任" class="headerlink" title="培养责任"></a>培养责任</h1><p>自律的自由</p>
<p>从知道到做到</p>
<p>自由的目的是责任，一个越自由的人越懂得服务大众</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">机器学习/神经网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-14 09:03:29" itemprop="dateCreated datePublished" datetime="2020-08-14T09:03:29+08:00">2020-08-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-19 21:10:53" itemprop="dateModified" datetime="2020-08-19T21:10:53+08:00">2020-08-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="非线性假设"><a href="#非线性假设" class="headerlink" title="非线性假设"></a>非线性假设</h1><ul>
<li>线性回归和逻辑回归的缺点：当特征过多时，计算会过于复杂</li>
</ul>
<h1 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h1><p><img src="/2020/08/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/1.png" alt="1"></p>
<p>其中$x_1,x_2,x_3$是输入单元，$a_1,a_2,a_3$是中间单元，负责数据处理，最后是输出单元。</p>
<p>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。</p>
<p>第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。我们为每一层都增加一个偏差单位（bias unit）</p>
<ul>
<li>符号表示：<br>$a_i^{(j)}代表第j层的第i个激活单元,\theta^{(j)}代表从第j层映射到第j + 1层时的权重的矩阵$</li>
</ul>
<p>对于上图所示的模型，激活单元和输出分别表达为：</p>
<p>$$<br>a_{1}^{(2)}=g\left(\Theta_{10}^{(1)} x_{0}+\Theta_{11}^{(1)} x_{1}+\Theta_{12}^{(1)} x_{2}+\Theta_{13}^{(1)} x_{3}\right)<br>$$</p>
<p>$$<br>a_{2}^{(2)}=g\left(\Theta_{20}^{(1)} x_{0}+\Theta_{21}^{(1)} x_{1}+\Theta_{22}^{(1)} x_{2}+\Theta_{23}^{(1)} x_{3}\right)<br>$$</p>
<p>$$<br>a_{3}^{(2)}=g\left(\Theta_{30}^{(1)} x_{0}+\Theta_{31}^{(1)} x_{1}+\Theta_{32}^{(1)} x_{2}+\Theta_{33}^{(1)} x_{3}\right)<br>$$</p>
<p>$$<br>h_{\Theta}(x)=a_1^{(3)} = g\left(\Theta_{10}^{(2)} a_{0}^{(2)}+\Theta_{11}^{(2)} a_{1}^{(2)}+\Theta_{12}^{(2)} a_{2}^{(2)}+\Theta_{13}^{(2)} a_{3}^{(2)}\right)<br>$$</p>
<p>如果一个网络在$j$层有$s_j$个神经元，$j + 1$层有$s_{j+1}$个神经元，那么$\Theta^{(j)}$的维数是$s_{j + 1}\times(s_j + 1)$</p>
<h1 id="多类分类"><a href="#多类分类" class="headerlink" title="多类分类"></a>多类分类</h1><p>输出层多个输出，分别表示每一项的是或者非</p>
<h1 id="符号表示"><a href="#符号表示" class="headerlink" title="符号表示"></a>符号表示</h1><p>$m$:样本数量</p>
<p>$L$:神经网络层数</p>
<p>$S_i$:每层的神经元数目</p>
<p>二分类：$S_L = 1, y = 0,1$表示哪一类</p>
<p>$K$分类($L &gt; 2$) : $S_L = K$, $y_i = 1$表示分到第$i$类</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><ul>
<li><p>逻辑回归<br>$$J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$$</p>
</li>
<li><p>神经网络<br>在神经网络中，我们可以有很多输出变量，我们的$h_\theta(x)$是一个维度为$K$的向量，并且我们训练集中的因变量也是同样维度的一个向量，因此我们的代价函数会比逻辑回归更加复杂一些</p>
</li>
</ul>
<p>$$J(\Theta)=-\frac{1}{m}\sum_{i=1}^{m}\sum_{k=1}^{k}\left[y_{k}^{(i)}\log\left(h_{\Theta}\left(x^{(i)}\right)\right)<em>{k}+\left(1-y</em>{k}^{(i)}\right)\log\left(1-\left(h_{\Theta}\left(x^{(i)}\right)\right)<em>{k}\right)\right]+\frac{\lambda}{2m}\sum</em>{l=1}^{L-1}\sum_{i=1}^{s_{l}}\sum_{j=1}^{s_{l}+1}\left(\Theta_{ji}^{(l)}\right)^{2}$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://luyilin.top/2020/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="luyilin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="引而不发，跃如也">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/08/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">机器学习/逻辑回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-12 08:50:44 / Modified: 17:06:52" itemprop="dateCreated datePublished" datetime="2020-08-12T08:50:44+08:00">2020-08-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>$y$ 是一个离散值</p>
<p>线性回归此时可能准确度降低，并且预测值可能远大于1或者小于0</p>
<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>线性回归：<br>$$h_\theta(x) = \theta^TX$$<br>逻辑回归：<br>$$h_\theta(x) = g(\theta^TX)$$</p>
<p>其中<br>$$g(x) = \frac{1}{1 + e^{-x}}$$</p>
<p>合并有<br>$$h_\theta(x) = \frac{1}{1 + e^{-\theta^TX}}$$</p>
<p>这里$h$的作用是输出$y = 1$的可能性，即<br>$$h_\theta (x) = P(y = 1|x;\theta )$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span> + np.exp(-z))</span><br></pre></td></tr></table></figure>

<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>线性回归<br>$$J(\theta) = \frac{1}{m}\sum_{i = 1}^m\frac{1}{2}(h_{\theta}(x^{(i)})-y^{(i)})^2$$</p>
<p>$$J(\theta) = \frac{1}{m}\sum_{i = 1}^mCost(h_{\theta}(x^{(i)}),y^{(i)})$$</p>
<p>逻辑回归<br>$$\operatorname{Cost}\left(h_{\theta}(x), y\right)=\left{\begin{aligned}<br>-\log \left(h_{\theta}(x)\right) &amp; \text { if } y=1 \<br>-\log \left(1-h_{\theta}(x)\right) &amp; \text { if } y=0<br>\end{aligned}\right.$$</p>
<ul>
<li>实际的 $y = 1$ 且 $h_\theta(x)$ 也为 1时误差为 0，当$y = 1$但$h_\theta(x)$不为1时误差随着$h_\theta(x)$变小而变大；当实际的$y = 0$  且$h_\theta(x)$也为 0 时代价为 0，当$y = 0$ 但$h_\theta(x)$不为0时误差随着$h_\theta(x)$的变大而变大。</li>
</ul>
<p>变形有<br>$$\operatorname{cost}\left(h_{\theta}(x), y\right)=-y \times \log \left(h_{\theta}(x)\right)-(1-y) \times \log \left(1-h_{\theta}(x)\right)$$</p>
<p>$$J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$$</p>
<p>$$h_\theta(x) = \theta^TX$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(theta, X, y)</span>:</span></span><br><span class="line">    theta = np.matrix(theta)</span><br><span class="line">    X = np.matrix(X)</span><br><span class="line">    y = np.matrix(y)</span><br><span class="line">    first = np.multiply(-y, np.log(sigmoid(X* theta.T)))</span><br><span class="line">    second = np.multiply((<span class="number">1</span> - y), np.log(<span class="number">1</span> - sigmoid(X* theta.T)))</span><br><span class="line">    <span class="keyword">return</span> np.sum(first - second) / (len(X))</span><br></pre></td></tr></table></figure>

<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>$$J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]$$<br>考虑： </p>
<p>$$h_{\theta}\left(x^{(i)}\right)=\frac{1}{1+e^{-\theta^{T} x^{(i)}}}$$</p>
<p>则:<br>$$<br>\begin{aligned}<br>&amp;y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right) \<br>&amp;=y^{(i)} \log \left(\frac{1}{1+e^{-\theta^{T} x^{(i)}}}\right)+\left(1-y^{(i)}\right) \log \left(1-\frac{1}{\left.1+e^{-\theta^{T} x^{(i)}}\right)}\right)\<br>&amp;=-y^{(i)} \log \left(1+e^{-\theta^{T} x^{(i)}}\right)-\left(1-y^{(i)}\right) \log \left(1+e^{\theta^{T} x^{(i)}}\right)<br>\end{aligned}<br>$$</p>
<p>所以:</p>
<p>$$<br>\begin{aligned}<br>\frac{\partial}{\partial \theta_{j}} J(\theta)<br>&amp;=\frac{\partial}{\partial \theta_{j}}\left[-\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \log \left(1+e^{-\theta^{T} x^{(i)}}\right)-\left(1-y^{(i)}\right) \log \left(1+e^{\theta^{T} x^{(i)}}\right)\right]\right]\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \frac{-x_{j}^{(i)} e^{-\theta^{T} x^{(i)}}}{1+e^{-\theta^{T} x^{(i)}}}-\left(1-y^{(i)}\right) \frac{x_{j}^{(i)} e^{\theta^{T} x^{(i)}}}{1+e^{\theta^{T} x^{(i)}}}\right]\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)}\frac{x_{j}^{(i)}}{1+e^{\theta^{T} x^{(i)}}}-\left(1-y^{(i)}\right) \frac{x_{j}^{(i)} e^{\theta^T} x^{(i)}}{1+e^{\theta^{T} x^{(i)}}}\right] \<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m} \frac{y^{(i)} x_{j}^{(i)}-x_{j}^{(i)} e^{\theta T_{x}(i)}+y^{(i)} x_{j}^{(i)} e^{\theta^{T} x^{(i)}}}{1+e^{\theta T_{x}(i)}} \<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m} \frac{y^{(i)}\left(1+e^{\theta^{T} x^{(i)}}\right)-e^{\ell^{T} x^{(i)}}}{1+e^{\theta^{T} x^{(i)}}} x_{j}^{(i)}\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left(y^{(i)}-\frac{e^{\theta^{T} x^{(i)}}}{1+e^{\theta^{T} x^{(i)}}}\right) x_{j}^{(i)} \<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left(y^{(i)}-\frac{1}{\left(1 + e^{-\theta^{T}x^{(i)}}\right)}\right)x_{j}^{(i)}\<br>&amp;=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)}-h_{\theta}\left(x^{(i)}\right)\right] x_{j}^{(i)}\<br>&amp;=\frac{1}{m} \sum_{i=1}^{m}\left[h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right] x_{j}^{(i)}<br>\end{aligned}<br>$$</p>
<p>得到了与线性回归类似的表达式($h_\theta(x)$不同)</p>
<ul>
<li>在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。</li>
</ul>
<h2 id="一对多的分类"><a href="#一对多的分类" class="headerlink" title="一对多的分类"></a>一对多的分类</h2><p>对各个类别进行一次二分类即可</p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>解决过拟合问题</p>
<h2 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h2><p>$$J(\theta) = \frac{1}{2m}\left[\sum_{i = 1}^m(h_\theta(x^{(i)})-y^{(i)})^2 + \lambda\sum_{j = 1}^n\theta_j^2\right]$$</p>
<ul>
<li>注： $\theta_j$的求和项从1开始</li>
</ul>
<h2 id="正则化线性回归"><a href="#正则化线性回归" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h2><h3 id="梯度下降-1"><a href="#梯度下降-1" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>$$<br>\begin{array}{l}<br>\theta_{0}:=\theta_{0}-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{0}^{(i)}\right) \<br>\theta_{j}:=\theta_{j}-a\left[\frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}+\frac{\lambda}{m} \theta_{j}\right]\right.<br>\end{array}<br>$$</p>
<p>对于$j = 1,2,…,n$可改为</p>
<p>$$\theta_{j}:=\theta_{j}\left(1-a \frac{\lambda}{m}\right)-a \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}$$</p>
<h3 id="正则方程"><a href="#正则方程" class="headerlink" title="正则方程"></a>正则方程</h3><p>$$<br>\theta=\left(X^{T} X+\lambda\left[\begin{array}{ccc}<br>0 \<br>&amp;1&amp; \<br>&amp;&amp; \ddots \<br>&amp;&amp;&amp;1<br>\end{array}\right]\right)^{-1} X^{T} y<br>$$</p>
<p>矩阵尺寸$(n + 1)(n + 1)$</p>
<h2 id="正则化的逻辑回归模型"><a href="#正则化的逻辑回归模型" class="headerlink" title="正则化的逻辑回归模型"></a>正则化的逻辑回归模型</h2><p>$$J(\theta)=\frac{1}{m} \sum_{i=1}^{m}\left[-y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)-\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np​</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">costReg</span><span class="params">(theta, X, y, learningRate)</span>:</span></span><br><span class="line">    theta = np.matrix(theta)</span><br><span class="line">    X = np.matrix(X)</span><br><span class="line">    y = np.matrix(y)</span><br><span class="line">    first = np.multiply(-y, np.log(sigmoid(X*theta.T)))</span><br><span class="line">    second = np.multiply((<span class="number">1</span> - y), np.log(<span class="number">1</span> - sigmoid(X*theta.T)))</span><br><span class="line">    reg = (learningRate / (<span class="number">2</span> * len(X))* np.sum(np.power(theta[:,<span class="number">1</span>:theta.shape[<span class="number">1</span>]],<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> np.sum(first - second) / (len(X)) + regpython</span><br></pre></td></tr></table></figure>


<p>$$<br>\theta_{0}:=\theta_{0}-a \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{0}^{(i)}\right) \<br>\theta_{j}:=\theta_{j}-a\left[\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}+\frac{\lambda}{m} \theta_{j}\right] \<br>$$</p>
<p>$\ for\ j = 1,2,…,n$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">luyilin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">luyilin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
